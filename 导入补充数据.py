#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¡¥å……è¯å…¸æ•°æ®å¯¼å…¥è„šæœ¬
å°†æ–°çš„è¯å…¸æ•°æ®å¯¼å…¥åˆ°Neo4jæ•°æ®åº“ä¸­
"""

import pandas as pd
import numpy as np
from neo4j import GraphDatabase
import json
from datetime import datetime
import os

class DictionaryDataImporter:
    def __init__(self, uri="bolt://localhost:7687", user="neo4j", password="password"):
        self.driver = GraphDatabase.driver(uri, auth=(user, password))
        
    def close(self):
        self.driver.close()
    
    def load_csv_data(self, csv_file):
        """åŠ è½½CSVæ•°æ®"""
        try:
            df = pd.read_csv(csv_file, encoding='utf-8')
            print(f"âœ… æˆåŠŸåŠ è½½ {csv_file}: {len(df)} æ¡è®°å½•")
            return df
        except Exception as e:
            print(f"âŒ åŠ è½½ {csv_file} å¤±è´¥: {e}")
            return None
    
    def validate_data(self, df):
        """éªŒè¯æ•°æ®è´¨é‡"""
        issues = []
        
        # æ£€æŸ¥å¿…å¡«å­—æ®µ
        required_fields = ['term', 'category']
        for field in required_fields:
            if field not in df.columns:
                issues.append(f"ç¼ºå°‘å¿…å¡«å­—æ®µ: {field}")
            elif df[field].isna().any():
                null_count = df[field].isna().sum()
                issues.append(f"å­—æ®µ {field} æœ‰ {null_count} ä¸ªç©ºå€¼")
        
        # æ£€æŸ¥categoryæ˜¯å¦åœ¨å…è®¸çš„Labelä¸­
        valid_labels = ['Symptom', 'Component', 'Tool', 'Process', 'TestCase', 'Metric', 'Material', 'Role']
        if 'category' in df.columns:
            invalid_categories = df[~df['category'].isin(valid_labels)]['category'].unique()
            if len(invalid_categories) > 0:
                issues.append(f"æ— æ•ˆçš„categoryå€¼: {invalid_categories}")
        
        # æ£€æŸ¥é‡å¤æœ¯è¯­
        if 'term' in df.columns:
            duplicates = df[df['term'].duplicated()]['term'].unique()
            if len(duplicates) > 0:
                issues.append(f"é‡å¤çš„æœ¯è¯­: {duplicates}")
        
        return issues
    
    def check_existing_terms(self, df):
        """æ£€æŸ¥æ•°æ®åº“ä¸­å·²å­˜åœ¨çš„æœ¯è¯­"""
        with self.driver.session() as session:
            existing_terms = []
            for _, row in df.iterrows():
                term = row['term']
                category = row['category']
                
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                query = f"""
                MATCH (n:{category} {{name: $term}})
                RETURN n.name as name
                """
                result = session.run(query, term=term)
                if result.single():
                    existing_terms.append(term)
            
            return existing_terms
    
    def import_data(self, df, skip_existing=True):
        """å¯¼å…¥æ•°æ®åˆ°Neo4j"""
        success_count = 0
        error_count = 0
        skipped_count = 0
        
        # æ£€æŸ¥å·²å­˜åœ¨çš„æœ¯è¯­
        existing_terms = self.check_existing_terms(df) if skip_existing else []
        
        with self.driver.session() as session:
            for index, row in df.iterrows():
                try:
                    term = row['term']
                    category = row['category']
                    
                    # è·³è¿‡å·²å­˜åœ¨çš„æœ¯è¯­
                    if skip_existing and term in existing_terms:
                        print(f"â­ï¸  è·³è¿‡å·²å­˜åœ¨çš„æœ¯è¯­: {term}")
                        skipped_count += 1
                        continue
                    
                    # å¤„ç†åˆ«å
                    aliases = []
                    if pd.notna(row.get('aliases', '')):
                        aliases = [alias.strip() for alias in str(row['aliases']).split(';') if alias.strip()]
                    
                    # å¤„ç†æ ‡ç­¾
                    tags = []
                    if pd.notna(row.get('tags', '')):
                        tags = [tag.strip() for tag in str(row['tags']).split(';') if tag.strip()]
                    
                    # æ„å»ºèŠ‚ç‚¹å±æ€§
                    properties = {
                        'name': term,
                        'aliases': aliases,
                        'tags': tags,
                        'definition': str(row.get('definition', '')).strip() if pd.notna(row.get('definition')) else '',
                        'example': str(row.get('example', '')).strip() if pd.notna(row.get('example')) else '',
                        'source': str(row.get('source', 'æ ‡å‡†åŒ–è¯å…¸')).strip(),
                        'status': str(row.get('status', 'active')).strip(),
                        'updated_at': str(row.get('updated_at', datetime.now().strftime('%Y-%m-%d %H:%M:%S'))).strip()
                    }
                    
                    # æ·»åŠ å­ç±»åˆ«
                    if pd.notna(row.get('sub_category')):
                        properties['sub_category'] = str(row['sub_category']).strip()
                    
                    # åˆ›å»ºèŠ‚ç‚¹
                    query = f"""
                    CREATE (n:{category} $properties)
                    RETURN n.name as name
                    """
                    
                    result = session.run(query, properties=properties)
                    if result.single():
                        print(f"âœ… æˆåŠŸå¯¼å…¥: {term} ({category})")
                        success_count += 1
                    else:
                        print(f"âŒ å¯¼å…¥å¤±è´¥: {term}")
                        error_count += 1
                        
                except Exception as e:
                    print(f"âŒ å¯¼å…¥ {row.get('term', 'Unknown')} æ—¶å‡ºé”™: {e}")
                    error_count += 1
        
        return {
            'success': success_count,
            'error': error_count,
            'skipped': skipped_count,
            'total': len(df)
        }
    
    def get_statistics(self):
        """è·å–å¯¼å…¥åçš„ç»Ÿè®¡ä¿¡æ¯"""
        with self.driver.session() as session:
            query = """
            MATCH (n)
            RETURN labels(n)[0] as label, count(n) as count
            ORDER BY count DESC
            """
            result = session.run(query)
            stats = []
            total = 0
            for record in result:
                label = record['label']
                count = record['count']
                stats.append({'label': label, 'count': count})
                total += count
            
            return {'labels': stats, 'total': total}

def main():
    print("ğŸš€ å¼€å§‹è¡¥å……è¯å…¸æ•°æ®å¯¼å…¥...")
    
    # åˆå§‹åŒ–å¯¼å…¥å™¨
    importer = DictionaryDataImporter()
    
    try:
        # å¯¼å…¥æ‰¹æ¬¡1æ•°æ®
        print("\nğŸ“‹ å¯¼å…¥æ‰¹æ¬¡1æ•°æ®...")
        df1 = importer.load_csv_data('è¡¥å……è¯å…¸æ•°æ®_æ‰¹æ¬¡1.csv')
        if df1 is not None:
            # éªŒè¯æ•°æ®
            issues1 = importer.validate_data(df1)
            if issues1:
                print("âš ï¸  æ•°æ®éªŒè¯å‘ç°é—®é¢˜:")
                for issue in issues1:
                    print(f"   - {issue}")
            
            # å¯¼å…¥æ•°æ®
            result1 = importer.import_data(df1, skip_existing=True)
            print(f"ğŸ“Š æ‰¹æ¬¡1å¯¼å…¥ç»“æœ: æˆåŠŸ{result1['success']}æ¡, å¤±è´¥{result1['error']}æ¡, è·³è¿‡{result1['skipped']}æ¡")
        
        # å¯¼å…¥æ‰¹æ¬¡2æ•°æ®
        print("\nğŸ“‹ å¯¼å…¥æ‰¹æ¬¡2æ•°æ®...")
        df2 = importer.load_csv_data('è¡¥å……è¯å…¸æ•°æ®_æ‰¹æ¬¡2.csv')
        if df2 is not None:
            # éªŒè¯æ•°æ®
            issues2 = importer.validate_data(df2)
            if issues2:
                print("âš ï¸  æ•°æ®éªŒè¯å‘ç°é—®é¢˜:")
                for issue in issues2:
                    print(f"   - {issue}")
            
            # å¯¼å…¥æ•°æ®
            result2 = importer.import_data(df2, skip_existing=True)
            print(f"ğŸ“Š æ‰¹æ¬¡2å¯¼å…¥ç»“æœ: æˆåŠŸ{result2['success']}æ¡, å¤±è´¥{result2['error']}æ¡, è·³è¿‡{result2['skipped']}æ¡")
        
        # è·å–æœ€ç»ˆç»Ÿè®¡
        print("\nğŸ“ˆ å¯¼å…¥åæ•°æ®åº“ç»Ÿè®¡:")
        stats = importer.get_statistics()
        print(f"æ€»èŠ‚ç‚¹æ•°: {stats['total']}")
        for label_stat in stats['labels']:
            print(f"  {label_stat['label']}: {label_stat['count']}ä¸ª")
        
        # ä¿å­˜ç»Ÿè®¡æŠ¥å‘Š
        report = {
            'import_time': datetime.now().isoformat(),
            'batch1_result': result1 if df1 is not None else None,
            'batch2_result': result2 if df2 is not None else None,
            'final_statistics': stats,
            'validation_issues': {
                'batch1': issues1 if df1 is not None else [],
                'batch2': issues2 if df2 is not None else []
            }
        }
        
        with open('è¡¥å……æ•°æ®å¯¼å…¥æŠ¥å‘Š.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… è¡¥å……æ•°æ®å¯¼å…¥å®Œæˆ! è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: è¡¥å……æ•°æ®å¯¼å…¥æŠ¥å‘Š.json")
        
    except Exception as e:
        print(f"âŒ å¯¼å…¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
    
    finally:
        importer.close()

if __name__ == "__main__":
    main()
