# çŸ¥è¯†å›¾è°±ç³»ç»Ÿä¼˜åŒ–å®æ–½è®¡åˆ’

**åˆ¶å®šæ—¥æœŸ**: 2025-10-09  
**æ‰§è¡Œå‘¨æœŸ**: 2å‘¨ (çŸ­æœŸä¼˜åŒ–)  
**è´Ÿè´£äºº**: å¼€å‘å›¢é˜Ÿ  

---

## ğŸ¯ ä¼˜åŒ–ç›®æ ‡

### æ€§èƒ½ç›®æ ‡
- APIå“åº”æ—¶é—´: ä»3-14ç§’ â†’ <1-5ç§’ (æå‡70%)
- ç¼“å­˜å‘½ä¸­ç‡: ä»<10% â†’ >80%
- é¦–å±åŠ è½½: <2ç§’
- å¹¶å‘æ”¯æŒ: >500ç”¨æˆ·

### è´¨é‡ç›®æ ‡
- ä»£ç è¦†ç›–ç‡: 0% â†’ 60%
- å®‰å…¨è¯„åˆ†: 3.5/5 â†’ 4.5/5
- å¯è§‚æµ‹æ€§: 3.0/5 â†’ 4.5/5

---

## ğŸ“… ç¬¬ä¸€å‘¨ï¼šæ€§èƒ½ä¼˜åŒ–

### Day 1-2: Redisç¼“å­˜å…¨é¢å¯ç”¨ â­â­â­â­â­

#### ä»»åŠ¡æ¸…å•
- [x] Rediså·²é…ç½® (å·²å®Œæˆ)
- [ ] å®ç°æŸ¥è¯¢ç¼“å­˜ç­–ç•¥
- [ ] å®ç°å›¾è°±æ•°æ®ç¼“å­˜
- [ ] å®ç°è¯å…¸æ•°æ®ç¼“å­˜
- [ ] å®ç°æ–‡ä»¶å¤„ç†ç¼“å­˜
- [ ] æµ‹è¯•ç¼“å­˜æ•ˆæœ

#### å®æ–½æ­¥éª¤

**1. ä¿®æ”¹ api/main.py - å¯ç”¨ç¼“å­˜è£…é¥°å™¨**
```python
# ç»Ÿè®¡æ•°æ®ç¼“å­˜ (5åˆ†é’Ÿ)
@app.get("/kg/stats")
@cache_result("stats", ttl=300)
async def get_statistics():
    # ... ç°æœ‰ä»£ç 

# å›¾è°±æ•°æ®ç¼“å­˜ (10åˆ†é’Ÿ)
@app.get("/kg/graph")
@cache_result("graph", ttl=600)
async def get_graph_data(limit: int = 100, show_all: bool = False):
    # ... ç°æœ‰ä»£ç 

# è¯å…¸æ•°æ®ç¼“å­˜ (30åˆ†é’Ÿ)
@app.get("/kg/dictionary")
@cache_result("dictionary", ttl=1800)
async def get_dictionary():
    # ... ç°æœ‰ä»£ç 
```

**2. æ·»åŠ ç¼“å­˜é¢„çƒ­**
```python
# api/cache/cache_warmer.py
async def warm_cache():
    """é¢„çƒ­å¸¸ç”¨ç¼“å­˜"""
    logger.info("å¼€å§‹ç¼“å­˜é¢„çƒ­...")
    
    # é¢„çƒ­ç»Ÿè®¡æ•°æ®
    await get_statistics()
    
    # é¢„çƒ­è¯å…¸æ•°æ®
    await get_dictionary()
    
    # é¢„çƒ­å°è§„æ¨¡å›¾è°±
    await get_graph_data(limit=100)
    
    logger.info("ç¼“å­˜é¢„çƒ­å®Œæˆ")

# åœ¨åº”ç”¨å¯åŠ¨æ—¶è°ƒç”¨
@asynccontextmanager
async def lifespan(app: FastAPI):
    await redis_manager.connect()
    await warm_cache()  # æ·»åŠ è¿™è¡Œ
    yield
    await redis_manager.disconnect()
```

**3. æ·»åŠ ç¼“å­˜ç›‘æ§**
```python
# api/main.py
@app.get("/metrics/cache")
async def cache_metrics():
    """ç¼“å­˜æŒ‡æ ‡"""
    info = await redis_manager.redis.info("stats")
    return {
        "hits": info.get("keyspace_hits", 0),
        "misses": info.get("keyspace_misses", 0),
        "hit_rate": info.get("keyspace_hits", 0) / 
                   (info.get("keyspace_hits", 0) + info.get("keyspace_misses", 1))
    }
```

#### é¢„æœŸæ•ˆæœ
- APIå“åº”æ—¶é—´: 3-14ç§’ â†’ 0.1-2ç§’ (é¦–æ¬¡è¯·æ±‚ä»éœ€3-14ç§’)
- ç¼“å­˜å‘½ä¸­ç‡: <10% â†’ 80%+
- æœåŠ¡å™¨è´Ÿè½½: é™ä½60%

---

### Day 3-4: Neo4jæŸ¥è¯¢ä¼˜åŒ– â­â­â­â­â­

#### ä»»åŠ¡æ¸…å•
- [ ] åˆ›å»ºå¿…è¦ç´¢å¼•
- [ ] ä¼˜åŒ–å¤æ‚æŸ¥è¯¢
- [ ] æ·»åŠ æŸ¥è¯¢åˆ†æ
- [ ] æµ‹è¯•æŸ¥è¯¢æ€§èƒ½

#### å®æ–½æ­¥éª¤

**1. åˆ›å»ºç´¢å¼•è„šæœ¬**
```python
# scripts/optimize_neo4j_indexes.py
from neo4j import GraphDatabase

class Neo4jIndexOptimizer:
    def __init__(self):
        self.driver = GraphDatabase.driver(
            "bolt://localhost:7687",
            auth=("neo4j", "password123")
        )
    
    def create_indexes(self):
        """åˆ›å»ºæ‰€æœ‰å¿…è¦ç´¢å¼•"""
        indexes = [
            # æœ¯è¯­ç´¢å¼•
            "CREATE INDEX term_name_idx IF NOT EXISTS FOR (n:Term) ON (n.name)",
            "CREATE INDEX term_category_idx IF NOT EXISTS FOR (n:Term) ON (n.category)",
            
            # æ ‡ç­¾ç´¢å¼•
            "CREATE INDEX tag_name_idx IF NOT EXISTS FOR (n:Tag) ON (n.name)",
            
            # åˆ†ç±»ç´¢å¼•
            "CREATE INDEX category_name_idx IF NOT EXISTS FOR (n:Category) ON (n.name)",
            
            # åˆ«åç´¢å¼•
            "CREATE INDEX alias_name_idx IF NOT EXISTS FOR (n:Alias) ON (n.name)",
            
            # ç»„ä»¶ç´¢å¼•
            "CREATE INDEX component_name_idx IF NOT EXISTS FOR (n:Component) ON (n.name)",
            
            # å¤åˆç´¢å¼•
            "CREATE INDEX term_name_category_idx IF NOT EXISTS FOR (n:Term) ON (n.name, n.category)",
            
            # å…¨æ–‡æœç´¢ç´¢å¼•
            "CREATE FULLTEXT INDEX term_fulltext_idx IF NOT EXISTS FOR (n:Term) ON EACH [n.name, n.description]",
        ]
        
        with self.driver.session() as session:
            for index_query in indexes:
                try:
                    session.run(index_query)
                    print(f"âœ… åˆ›å»ºç´¢å¼•: {index_query[:50]}...")
                except Exception as e:
                    print(f"âŒ ç´¢å¼•åˆ›å»ºå¤±è´¥: {e}")
    
    def analyze_queries(self):
        """åˆ†ææ…¢æŸ¥è¯¢"""
        slow_queries = [
            # å›¾è°±æŸ¥è¯¢
            """
            EXPLAIN MATCH (n)
            WHERE n:Product OR n:Component OR n:Anomaly
            WITH n, size((n)--()) as degree
            WHERE degree > 0
            RETURN id(n), labels(n)[0], n.name, degree
            ORDER BY degree DESC
            LIMIT 100
            """,
            
            # è¯å…¸æŸ¥è¯¢
            """
            EXPLAIN MATCH (t:Term)
            OPTIONAL MATCH (t)-[:HAS_TAG]->(tag:Tag)
            OPTIONAL MATCH (t)-[:BELONGS_TO]->(cat:Category)
            RETURN t, collect(tag.name), cat.name
            LIMIT 1000
            """,
        ]
        
        with self.driver.session() as session:
            for query in slow_queries:
                result = session.run(query)
                print(f"\næŸ¥è¯¢è®¡åˆ’:\n{result.consume().plan}")

if __name__ == "__main__":
    optimizer = Neo4jIndexOptimizer()
    optimizer.create_indexes()
    optimizer.analyze_queries()
```

**2. ä¼˜åŒ–å›¾è°±æŸ¥è¯¢**
```python
# å½“å‰æŸ¥è¯¢ (æ…¢)
query = """
MATCH (n)
RETURN n
LIMIT 1000
"""

# ä¼˜åŒ–åæŸ¥è¯¢ (å¿«)
query = """
MATCH (n)
WHERE n:Product OR n:Component OR n:Anomaly OR n:TestCase
WITH n, size((n)--()) as degree
WHERE degree > 0
RETURN id(n) as id, 
       labels(n)[0] as label,
       n.name as name,
       degree
ORDER BY degree DESC
LIMIT $limit
"""
```

**3. æ·»åŠ æŸ¥è¯¢ç¼“å­˜**
```python
# åœ¨Neo4jå®¢æˆ·ç«¯æ·»åŠ æŸ¥è¯¢ç¼“å­˜
class Neo4jClient:
    def __init__(self):
        self.query_cache = {}
    
    async def execute_cached_query(self, query: str, params: dict, ttl: int = 300):
        cache_key = f"{query}:{json.dumps(params)}"
        
        if cache_key in self.query_cache:
            cached_time, result = self.query_cache[cache_key]
            if time.time() - cached_time < ttl:
                return result
        
        result = self.execute_query(query, params)
        self.query_cache[cache_key] = (time.time(), result)
        return result
```

#### é¢„æœŸæ•ˆæœ
- æŸ¥è¯¢æ—¶é—´: 3-14ç§’ â†’ 1-5ç§’
- ç´¢å¼•å‘½ä¸­ç‡: >90%
- æ•°æ®åº“CPU: é™ä½50%

---

### Day 5-6: å‰ç«¯æ€§èƒ½ä¼˜åŒ– â­â­â­â­

#### ä»»åŠ¡æ¸…å•
- [ ] å®ç°è·¯ç”±æ‡’åŠ è½½
- [ ] å®ç°ç»„ä»¶æ‡’åŠ è½½
- [ ] æ·»åŠ è™šæ‹Ÿæ»šåŠ¨
- [ ] ä¼˜åŒ–å›¾è°±æ¸²æŸ“
- [ ] æ·»åŠ è¯·æ±‚å»é‡

#### å®æ–½æ­¥éª¤

**1. è·¯ç”±æ‡’åŠ è½½**
```javascript
// apps/web/src/router/index.js
const routes = [
  {
    path: '/',
    name: 'Home',
    component: () => import('../views/Home.vue')  // æ‡’åŠ è½½
  },
  {
    path: '/graph-viz',
    name: 'GraphVisualization',
    component: () => import('../views/GraphVisualization.vue')
  },
  {
    path: '/dictionary',
    name: 'DictionaryManagement',
    component: () => import('../views/DictionaryManagement.vue')
  }
]
```

**2. è™šæ‹Ÿæ»šåŠ¨ (å¤§åˆ—è¡¨)**
```vue
<!-- apps/web/src/views/DictionaryManagement.vue -->
<template>
  <el-table-v2
    :columns="columns"
    :data="tableData"
    :width="700"
    :height="600"
    fixed
  />
</template>

<script setup>
import { ElTableV2 } from 'element-plus'

// è™šæ‹Ÿæ»šåŠ¨è‡ªåŠ¨å¤„ç†å¤§æ•°æ®
const tableData = ref([])  // å¯ä»¥æ˜¯10000+æ¡æ•°æ®
</script>
```

**3. è¯·æ±‚å»é‡**
```javascript
// apps/web/src/api/index.js
import { useDebounceFn } from '@vueuse/core'

// é˜²æŠ–æœç´¢
const debouncedSearch = useDebounceFn((keyword) => {
  return api.get('/kg/search', { params: { q: keyword } })
}, 300)

// è¯·æ±‚ç¼“å­˜
const requestCache = new Map()

api.interceptors.request.use(config => {
  const cacheKey = `${config.method}:${config.url}:${JSON.stringify(config.params)}`
  
  if (requestCache.has(cacheKey)) {
    const { timestamp, data } = requestCache.get(cacheKey)
    if (Date.now() - timestamp < 60000) {  // 1åˆ†é’Ÿç¼“å­˜
      return Promise.resolve({ data })
    }
  }
  
  return config
})

api.interceptors.response.use(response => {
  const cacheKey = `${response.config.method}:${response.config.url}:${JSON.stringify(response.config.params)}`
  requestCache.set(cacheKey, {
    timestamp: Date.now(),
    data: response.data
  })
  return response
})
```

**4. å›¾è°±æ¸²æŸ“ä¼˜åŒ–**
```javascript
// apps/web/src/components/GraphVisualization.vue
<script setup>
import { ref, computed } from 'vue'

// åˆ†æ‰¹æ¸²æŸ“èŠ‚ç‚¹
const renderBatch = async (nodes, batchSize = 100) => {
  for (let i = 0; i < nodes.length; i += batchSize) {
    const batch = nodes.slice(i, i + batchSize)
    cy.add(batch)
    await nextTick()  // è®©æµè§ˆå™¨æœ‰æ—¶é—´æ¸²æŸ“
  }
}

// èŠ‚ç‚¹è¿‡æ»¤ (åªæ˜¾ç¤ºé‡è¦èŠ‚ç‚¹)
const importantNodes = computed(() => {
  return allNodes.value.filter(node => node.degree > 2)
})
</script>
```

#### é¢„æœŸæ•ˆæœ
- é¦–å±åŠ è½½: 5ç§’ â†’ <2ç§’
- å¤§åˆ—è¡¨æ¸²æŸ“: å¡é¡¿ â†’ æµç•…
- å†…å­˜å ç”¨: é™ä½40%

---

### Day 7: æµ‹è¯•ä¸éªŒè¯ â­â­â­â­â­

#### ä»»åŠ¡æ¸…å•
- [ ] æ€§èƒ½æµ‹è¯•
- [ ] å‹åŠ›æµ‹è¯•
- [ ] ç¼“å­˜æµ‹è¯•
- [ ] ç”¨æˆ·ä½“éªŒæµ‹è¯•

#### æµ‹è¯•è„šæœ¬

**1. æ€§èƒ½æµ‹è¯•**
```python
# tests/performance_test.py
import time
import requests
import statistics

def test_api_performance():
    """æµ‹è¯•APIæ€§èƒ½"""
    endpoints = [
        "/health",
        "/kg/stats",
        "/kg/graph?limit=100",
        "/kg/dictionary",
    ]
    
    results = {}
    
    for endpoint in endpoints:
        times = []
        for _ in range(10):
            start = time.time()
            response = requests.get(f"http://47.108.152.16{endpoint}")
            duration = time.time() - start
            times.append(duration)
        
        results[endpoint] = {
            "avg": statistics.mean(times),
            "min": min(times),
            "max": max(times),
            "p95": statistics.quantiles(times, n=20)[18]
        }
    
    print("\næ€§èƒ½æµ‹è¯•ç»“æœ:")
    for endpoint, metrics in results.items():
        print(f"\n{endpoint}:")
        print(f"  å¹³å‡: {metrics['avg']:.3f}s")
        print(f"  æœ€å°: {metrics['min']:.3f}s")
        print(f"  æœ€å¤§: {metrics['max']:.3f}s")
        print(f"  P95: {metrics['p95']:.3f}s")

if __name__ == "__main__":
    test_api_performance()
```

**2. å‹åŠ›æµ‹è¯•**
```python
# tests/stress_test.py
import asyncio
import aiohttp

async def stress_test(concurrent_users=100):
    """å‹åŠ›æµ‹è¯•"""
    async with aiohttp.ClientSession() as session:
        tasks = []
        for _ in range(concurrent_users):
            task = session.get("http://47.108.152.16/kg/stats")
            tasks.append(task)
        
        start = time.time()
        responses = await asyncio.gather(*tasks)
        duration = time.time() - start
        
        success = sum(1 for r in responses if r.status == 200)
        
        print(f"\nå‹åŠ›æµ‹è¯•ç»“æœ:")
        print(f"  å¹¶å‘ç”¨æˆ·: {concurrent_users}")
        print(f"  æ€»è€—æ—¶: {duration:.2f}s")
        print(f"  æˆåŠŸç‡: {success/concurrent_users*100:.1f}%")
        print(f"  QPS: {concurrent_users/duration:.1f}")

if __name__ == "__main__":
    asyncio.run(stress_test())
```

**3. ç¼“å­˜æµ‹è¯•**
```python
# tests/cache_test.py
def test_cache_effectiveness():
    """æµ‹è¯•ç¼“å­˜æ•ˆæœ"""
    endpoint = "/kg/stats"
    
    # ç¬¬ä¸€æ¬¡è¯·æ±‚ (ç¼“å­˜æœªå‘½ä¸­)
    start = time.time()
    response1 = requests.get(f"http://47.108.152.16{endpoint}")
    time1 = time.time() - start
    
    # ç¬¬äºŒæ¬¡è¯·æ±‚ (ç¼“å­˜å‘½ä¸­)
    start = time.time()
    response2 = requests.get(f"http://47.108.152.16{endpoint}")
    time2 = time.time() - start
    
    print(f"\nç¼“å­˜æµ‹è¯•ç»“æœ:")
    print(f"  é¦–æ¬¡è¯·æ±‚: {time1:.3f}s")
    print(f"  ç¼“å­˜è¯·æ±‚: {time2:.3f}s")
    print(f"  æ€§èƒ½æå‡: {(time1-time2)/time1*100:.1f}%")
    
    assert time2 < time1 * 0.2, "ç¼“å­˜åº”è¯¥æå‡è‡³å°‘80%æ€§èƒ½"

if __name__ == "__main__":
    test_cache_effectiveness()
```

---

## ğŸ“… ç¬¬äºŒå‘¨ï¼šå®‰å…¨ä¸ç›‘æ§

### Day 8-9: å®‰å…¨åŠ å›º â­â­â­â­â­

#### ä»»åŠ¡æ¸…å•
- [ ] æ·»åŠ APIé™æµ
- [ ] é˜²æ­¢Cypheræ³¨å…¥
- [ ] æ·»åŠ è¾“å…¥éªŒè¯
- [ ] æ·»åŠ å®¡è®¡æ—¥å¿—
- [ ] å®‰å…¨æµ‹è¯•

#### å®æ–½æ­¥éª¤

**1. æ·»åŠ APIé™æµ**
```python
# api/main.py
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

# åº”ç”¨é™æµ
@app.get("/kg/graph")
@limiter.limit("10/minute")  # æ¯åˆ†é’Ÿ10æ¬¡
async def get_graph_data(request: Request, limit: int = 100):
    # ... ç°æœ‰ä»£ç 
```

**2. é˜²æ­¢Cypheræ³¨å…¥**
```python
# åˆ›å»ºå®‰å…¨æŸ¥è¯¢å·¥å…·
class SafeCypherQuery:
    @staticmethod
    def sanitize_input(user_input: str) -> str:
        """æ¸…ç†ç”¨æˆ·è¾“å…¥"""
        # ç§»é™¤å±é™©å­—ç¬¦
        dangerous_chars = [';', '--', '/*', '*/', 'DROP', 'DELETE']
        for char in dangerous_chars:
            user_input = user_input.replace(char, '')
        return user_input
    
    @staticmethod
    def execute_safe_query(session, query: str, params: dict):
        """æ‰§è¡Œå®‰å…¨æŸ¥è¯¢ (ä½¿ç”¨å‚æ•°åŒ–)"""
        # ç¡®ä¿ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢
        return session.run(query, **params)

# ä½¿ç”¨ç¤ºä¾‹
query = "MATCH (n:Term {name: $name}) RETURN n"
result = SafeCypherQuery.execute_safe_query(session, query, {"name": user_input})
```

**3. æ·»åŠ å®¡è®¡æ—¥å¿—**
```python
# api/middleware/audit.py
import logging
from datetime import datetime

audit_logger = logging.getLogger("audit")

@app.middleware("http")
async def audit_middleware(request: Request, call_next):
    start_time = time.time()
    
    # è®°å½•è¯·æ±‚
    audit_log = {
        "timestamp": datetime.now().isoformat(),
        "method": request.method,
        "path": request.url.path,
        "client_ip": request.client.host,
        "user_agent": request.headers.get("user-agent"),
    }
    
    response = await call_next(request)
    
    # è®°å½•å“åº”
    audit_log.update({
        "status_code": response.status_code,
        "duration": time.time() - start_time
    })
    
    audit_logger.info(json.dumps(audit_log))
    
    return response
```

---

### Day 10-11: ç›‘æ§å®Œå–„ â­â­â­â­

#### ä»»åŠ¡æ¸…å•
- [ ] é…ç½®Prometheus
- [ ] é…ç½®Grafana
- [ ] åˆ›å»ºç›‘æ§é¢æ¿
- [ ] é…ç½®å‘Šè­¦è§„åˆ™

#### å®æ–½æ­¥éª¤

**1. Prometheusé…ç½®**
```yaml
# monitoring/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'kg-api'
    static_configs:
      - targets: ['api:8000']
    metrics_path: '/metrics'
  
  - job_name: 'neo4j'
    static_configs:
      - targets: ['neo4j:7474']
    metrics_path: '/metrics'
  
  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']
```

**2. Grafanaé¢æ¿é…ç½®**
```json
{
  "dashboard": {
    "title": "çŸ¥è¯†å›¾è°±ç³»ç»Ÿç›‘æ§",
    "panels": [
      {
        "title": "APIè¯·æ±‚æ•°",
        "targets": [
          {
            "expr": "rate(kg_api_requests_total[5m])"
          }
        ]
      },
      {
        "title": "APIå“åº”æ—¶é—´",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, kg_api_request_duration_seconds)"
          }
        ]
      },
      {
        "title": "ç¼“å­˜å‘½ä¸­ç‡",
        "targets": [
          {
            "expr": "kg_cache_hits_total / (kg_cache_hits_total + kg_cache_misses_total)"
          }
        ]
      }
    ]
  }
}
```

**3. å‘Šè­¦è§„åˆ™**
```yaml
# monitoring/alerts.yml
groups:
  - name: kg_alerts
    rules:
      - alert: HighAPILatency
        expr: histogram_quantile(0.95, kg_api_request_duration_seconds) > 5
        for: 5m
        annotations:
          summary: "APIå“åº”æ—¶é—´è¿‡é«˜"
      
      - alert: LowCacheHitRate
        expr: kg_cache_hits_total / (kg_cache_hits_total + kg_cache_misses_total) < 0.5
        for: 10m
        annotations:
          summary: "ç¼“å­˜å‘½ä¸­ç‡è¿‡ä½"
      
      - alert: HighErrorRate
        expr: rate(kg_api_errors_total[5m]) > 0.1
        for: 5m
        annotations:
          summary: "APIé”™è¯¯ç‡è¿‡é«˜"
```

---

### Day 12-13: ä»£ç é‡æ„ â­â­â­â­

#### ä»»åŠ¡æ¸…å•
- [ ] æ‹†åˆ†main.py
- [ ] ç»Ÿä¸€é”™è¯¯å¤„ç†
- [ ] æ·»åŠ ç±»å‹æ³¨è§£
- [ ] ä»£ç å®¡æŸ¥

#### å®æ–½æ­¥éª¤

**1. æ‹†åˆ†main.py**
```python
# api/routers/graph_router.py
from fastapi import APIRouter

router = APIRouter(prefix="/kg", tags=["çŸ¥è¯†å›¾è°±"])

@router.get("/stats")
async def get_statistics():
    # ... ä»main.pyç§»åŠ¨è¿‡æ¥

@router.get("/graph")
async def get_graph_data():
    # ... ä»main.pyç§»åŠ¨è¿‡æ¥

# api/main.py (é‡æ„å)
from routers import graph_router, dictionary_router, file_router

app.include_router(graph_router.router)
app.include_router(dictionary_router.router)
app.include_router(file_router.router)
```

**2. ç»Ÿä¸€é”™è¯¯å¤„ç†**
```python
# api/exceptions.py
class KGException(Exception):
    def __init__(self, code: int, message: str, details: dict = None):
        self.code = code
        self.message = message
        self.details = details or {}

class NotFoundException(KGException):
    def __init__(self, resource: str):
        super().__init__(404, f"{resource} not found")

class ValidationException(KGException):
    def __init__(self, errors: list):
        super().__init__(400, "Validation failed", {"errors": errors})

# api/main.py
@app.exception_handler(KGException)
async def kg_exception_handler(request: Request, exc: KGException):
    return JSONResponse(
        status_code=exc.code,
        content={
            "success": False,
            "message": exc.message,
            "details": exc.details
        }
    )
```

---

### Day 14: æœ€ç»ˆæµ‹è¯•ä¸éƒ¨ç½² â­â­â­â­â­

#### ä»»åŠ¡æ¸…å•
- [ ] å®Œæ•´å›å½’æµ‹è¯•
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•
- [ ] éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
- [ ] ç›‘æ§éªŒè¯
- [ ] æ–‡æ¡£æ›´æ–°

#### éƒ¨ç½²æ£€æŸ¥æ¸…å•
```bash
# 1. å¤‡ä»½æ•°æ®
neo4j-admin dump --database=neo4j --to=/backup/neo4j-$(date +%Y%m%d).dump

# 2. æ›´æ–°ä»£ç 
git pull origin main

# 3. é‡å¯æœåŠ¡
systemctl restart kg-api
systemctl restart kg-frontend

# 4. éªŒè¯æœåŠ¡
curl http://47.108.152.16/health
curl http://47.108.152.16/kg/stats

# 5. æ£€æŸ¥ç›‘æ§
# è®¿é—® Grafana æŸ¥çœ‹æŒ‡æ ‡

# 6. æ£€æŸ¥æ—¥å¿—
tail -f /var/log/kg-api.log
```

---

## ğŸ“Š æˆåŠŸæŒ‡æ ‡

### æ€§èƒ½æŒ‡æ ‡
- [ ] APIå“åº”æ—¶é—´ <5ç§’ (P95)
- [ ] ç¼“å­˜å‘½ä¸­ç‡ >80%
- [ ] é¦–å±åŠ è½½ <2ç§’
- [ ] å¹¶å‘æ”¯æŒ >500ç”¨æˆ·

### è´¨é‡æŒ‡æ ‡
- [ ] ä»£ç è¦†ç›–ç‡ >60%
- [ ] å®‰å…¨è¯„åˆ† >4.5/5
- [ ] å¯è§‚æµ‹æ€§ >4.5/5

### ä¸šåŠ¡æŒ‡æ ‡
- [ ] ç”¨æˆ·æ»¡æ„åº¦ >90%
- [ ] ç³»ç»Ÿå¯ç”¨æ€§ >99.5%
- [ ] é”™è¯¯ç‡ <0.1%

---

## ğŸ“ é£é™©ä¸åº”å¯¹

### é£é™©1: ç¼“å­˜å¤±æ•ˆå¯¼è‡´æ€§èƒ½ä¸‹é™
**åº”å¯¹**: å®ç°ç¼“å­˜é¢„çƒ­å’Œé™çº§ç­–ç•¥

### é£é™©2: ç´¢å¼•åˆ›å»ºå½±å“ç”Ÿäº§
**åº”å¯¹**: åœ¨ä½å³°æœŸåˆ›å»ºç´¢å¼•

### é£é™©3: ä»£ç é‡æ„å¼•å…¥bug
**åº”å¯¹**: å……åˆ†æµ‹è¯•ï¼Œç°åº¦å‘å¸ƒ

---

**è®¡åˆ’åˆ¶å®š**: 2025-10-09  
**è®¡åˆ’æ‰§è¡Œ**: 2025-10-10 å¼€å§‹  
**é¢„è®¡å®Œæˆ**: 2025-10-24

