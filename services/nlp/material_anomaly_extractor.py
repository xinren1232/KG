#!/usr/bin/env python3
"""
æ¥æ–™å¼‚å¸¸æ•°æ®æŠ½å–å™¨ (åŸºäº ontology_v0.2)
ä¸“é—¨å¤„ç†æ¥æ–™å¼‚å¸¸Excelæ•°æ®ï¼ŒæŒ‰ç…§æ–°æœ¬ä½“è®¾è®¡æŠ½å–å®ä½“å’Œå…³ç³»

å®ä½“ç±»å‹ï¼šFactory, Project, Material, Anomaly, Symptom, RootCause, 
         Countermeasure, Owner, Supplier, Doc

å…³ç³»ç±»å‹ï¼šHAPPENED_IN, RELATED_TO, INVOLVES, HAS_SYMPTOM, HAS_ROOTCAUSE,
         RESOLVED_BY, OWNED_BY, SUPPLIED_BY, DOCUMENTED_IN
"""
import re
import json
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any
from pathlib import Path
import logging
from datetime import datetime
from dataclasses import dataclass

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class ExtractedEntity:
    """æŠ½å–çš„å®ä½“"""
    key: str
    type: str
    name: str
    properties: Dict[str, Any]

@dataclass
class ExtractedRelation:
    """æŠ½å–çš„å…³ç³»"""
    source_key: str
    target_key: str
    relation_type: str
    properties: Dict[str, Any] = None

class MaterialAnomalyExtractor:
    """æ¥æ–™å¼‚å¸¸æ•°æ®æŠ½å–å™¨"""
    
    def __init__(self):
        self.field_mappings = self._load_field_mappings()
        self.entity_patterns = self._load_entity_patterns()
        self.vocabulary = self._load_vocabulary()
        
    def _load_field_mappings(self) -> Dict[str, str]:
        """åŠ è½½å­—æ®µæ˜ å°„å…³ç³»"""
        return {
            # å·¥å‚ç›¸å…³
            'å·¥å‚åç§°': 'factory_name',
            'å·¥å‚': 'factory_name',
            'å‘ç”Ÿåœ°ç‚¹': 'factory_name',
            
            # é¡¹ç›®ç›¸å…³
            'é¡¹ç›®åç§°': 'project_name',
            'é¡¹ç›®': 'project_name',
            'é˜¶æ®µ': 'project_phase',
            'é¡¹ç›®é˜¶æ®µ': 'project_phase',
            
            # ç‰©æ–™ç›¸å…³
            'ç‰©æ–™ç¼–ç ': 'material_code',
            'ç‰©æ–™ç¼–ç 8ç ': 'material_code',
            'ç‰©æ–™æè¿°': 'material_desc',
            'ç‰©æ–™åç§°': 'material_desc',
            'ç‰©æ–™ç±»åˆ«': 'material_category',
            
            # å¼‚å¸¸ç›¸å…³
            'é—®é¢˜æè¿°': 'anomaly_title',
            'å¼‚å¸¸æè¿°': 'anomaly_title',
            'ä¸è‰¯æ•°é‡': 'defects_number',
            'ä¸è‰¯ç‡': 'defect_rate',
            'å‘ç°æ—¥æœŸ': 'anomaly_date',
            'ä½ç½®': 'anomaly_position',
            'ä¸¥é‡ç¨‹åº¦': 'severity',
            
            # æ ¹å› å’Œå¯¹ç­–
            'åŸå› åˆ†æ': 'root_cause',
            'æ ¹å› æè¿°': 'root_cause',
            'æ ¹æœ¬åŸå› ': 'root_cause',
            'ä¸´æ—¶æªæ–½': 'temp_countermeasure',
            'æŠ€æœ¯æªæ–½': 'tech_countermeasure',
            'ç®¡ç†æªæ–½': 'mgmt_countermeasure',
            'å¯¹ç­–': 'countermeasure',
            
            # è´£ä»»äºº
            'é—®é¢˜åˆ†æè´£ä»»äºº': 'owner_name',
            'è´£ä»»äºº': 'owner_name',
            'å¤„ç†äºº': 'owner_name',
            
            # ä¾›åº”å•†
            'ä¾›åº”å•†': 'supplier_name',
            'ä¾›åº”å•†åç§°': 'supplier_name'
        }
    
    def _load_entity_patterns(self) -> Dict[str, List[str]]:
        """åŠ è½½å®ä½“è¯†åˆ«æ¨¡å¼"""
        return {
            'Factory': [
                r'.*å·¥å‚$',
                r'.*å‚åŒº$',
                r'.*ç”Ÿäº§åŸºåœ°$',
                r'.*åˆ¶é€ ä¸­å¿ƒ$'
            ],
            'Project': [
                r'[A-Z]{2,4}\d*',  # BG6, MP3ç­‰
                r'é¡¹ç›®[A-Z0-9]+',
                r'[A-Z]+é¡¹ç›®'
            ],
            'Material': [
                r'\d{8}',  # 8ä½ç‰©æ–™ç¼–ç 
                r'\d{6,10}',  # 6-10ä½ç¼–ç 
                r'.*ç»„ä»¶$',
                r'.*æ¨¡å—$',
                r'.*éƒ¨ä»¶$'
            ],
            'Symptom': [
                r'è£‚çº¹|ç ´æŸ|å˜å½¢|åˆ’ä¼¤|æ±¡æŸ“',
                r'ä¸è‰¯|ç¼ºé™·|å¼‚å¸¸|æ•…éšœ',
                r'.*å¤±æ•ˆ$',
                r'.*ä¸åˆæ ¼$'
            ],
            'RootCause': [
                r'.*å¯¼è‡´.*',
                r'.*åŸå› .*',
                r'.*ä¸å½“.*',
                r'.*åå·®.*',
                r'.*ä¸è¶³.*'
            ],
            'Countermeasure': [
                r'æ›´æ¢.*',
                r'è°ƒæ•´.*',
                r'å¢åŠ .*',
                r'æ”¹è¿›.*',
                r'ä¼˜åŒ–.*',
                r'.*æªæ–½$'
            ],
            'Owner': [
                r'[\u4e00-\u9fa5]{2,4}',  # ä¸­æ–‡å§“å2-4å­—
                r'[A-Za-z]+\s+[A-Za-z]+',  # è‹±æ–‡å§“å
            ],
            'Supplier': [
                r'.*æœ‰é™å…¬å¸$',
                r'.*è‚¡ä»½.*å…¬å¸$',
                r'.*ç§‘æŠ€.*å…¬å¸$',
                r'.*åˆ¶é€ .*å…¬å¸$',
                r'.*ç”µå­.*å…¬å¸$'
            ]
        }
    
    def _load_vocabulary(self) -> Dict[str, List[str]]:
        """åŠ è½½æ ‡å‡†è¯æ±‡è¡¨"""
        return {
            'severity_levels': ['S1', 'S2', 'S3', 'S4', 'é«˜', 'ä¸­', 'ä½'],
            'project_phases': ['è®¾è®¡', 'å¼€å‘', 'è¯•äº§', 'é‡äº§', 'ç»´æŠ¤'],
            'countermeasure_types': ['ä¸´æ—¶æªæ–½', 'æŠ€æœ¯æªæ–½', 'ç®¡ç†æªæ–½', 'é¢„é˜²æªæ–½'],
            'material_categories': ['ç”µæ± ç»„ä»¶', 'æ˜¾ç¤ºç»„ä»¶', 'æ‘„åƒå¤´ç»„ä»¶', 'ç»“æ„ä»¶', 'ç”µå­å™¨ä»¶'],
            'symptom_categories': ['å¤–è§‚ç¼ºé™·', 'åŠŸèƒ½å¼‚å¸¸', 'æ€§èƒ½ä¸è¾¾æ ‡', 'å°ºå¯¸åå·®']
        }
    
    def extract_from_excel(self, file_path: str) -> Dict[str, Any]:
        """ä»Excelæ–‡ä»¶æŠ½å–æ¥æ–™å¼‚å¸¸æ•°æ®"""
        logger.info(f"å¼€å§‹æŠ½å–æ¥æ–™å¼‚å¸¸æ•°æ®: {file_path}")
        
        try:
            # è¯»å–Excelæ–‡ä»¶
            df = pd.read_excel(file_path)
            logger.info(f"è¯»å–åˆ° {len(df)} è¡Œæ•°æ®ï¼Œ{len(df.columns)} åˆ—")
            
            # æ ‡å‡†åŒ–åˆ—å
            df = self._normalize_columns(df)
            
            # æŠ½å–å®ä½“å’Œå…³ç³»
            entities = []
            relations = []
            
            for index, row in df.iterrows():
                row_entities, row_relations = self._extract_from_row(row, index, file_path)
                entities.extend(row_entities)
                relations.extend(row_relations)
            
            # å»é‡
            entities = self._deduplicate_entities(entities)
            relations = self._deduplicate_relations(relations)
            
            result = {
                'entities': [entity.__dict__ for entity in entities],
                'relations': [relation.__dict__ for relation in relations],
                'metadata': {
                    'source_file': file_path,
                    'total_rows': len(df),
                    'entity_count': len(entities),
                    'relation_count': len(relations),
                    'extracted_at': datetime.now().isoformat()
                }
            }
            
            logger.info(f"æŠ½å–å®Œæˆ: {len(entities)} ä¸ªå®ä½“, {len(relations)} ä¸ªå…³ç³»")
            return result
            
        except Exception as e:
            logger.error(f"æŠ½å–å¤±è´¥: {e}")
            raise
    
    def _normalize_columns(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ ‡å‡†åŒ–åˆ—å"""
        column_mapping = {}
        
        for col in df.columns:
            if col in self.field_mappings:
                column_mapping[col] = self.field_mappings[col]
            else:
                # å°è¯•æ¨¡ç³ŠåŒ¹é…
                normalized = self._fuzzy_match_column(col)
                if normalized:
                    column_mapping[col] = normalized
        
        if column_mapping:
            df = df.rename(columns=column_mapping)
            logger.info(f"åˆ—åæ ‡å‡†åŒ–: {column_mapping}")
        
        return df
    
    def _fuzzy_match_column(self, column_name: str) -> Optional[str]:
        """æ¨¡ç³ŠåŒ¹é…åˆ—å"""
        col_lower = column_name.lower()
        
        # ç®€å•çš„å…³é”®è¯åŒ¹é…
        if any(keyword in col_lower for keyword in ['å·¥å‚', 'factory']):
            return 'factory_name'
        elif any(keyword in col_lower for keyword in ['é¡¹ç›®', 'project']):
            return 'project_name'
        elif any(keyword in col_lower for keyword in ['ç‰©æ–™', 'material', 'ç¼–ç ']):
            if 'ç¼–ç ' in col_lower or 'code' in col_lower:
                return 'material_code'
            else:
                return 'material_desc'
        elif any(keyword in col_lower for keyword in ['é—®é¢˜', 'å¼‚å¸¸', 'æè¿°']):
            return 'anomaly_title'
        elif any(keyword in col_lower for keyword in ['åŸå› ', 'æ ¹å› ']):
            return 'root_cause'
        elif any(keyword in col_lower for keyword in ['æªæ–½', 'å¯¹ç­–']):
            return 'countermeasure'
        elif any(keyword in col_lower for keyword in ['è´£ä»»äºº', 'å¤„ç†äºº']):
            return 'owner_name'
        elif any(keyword in col_lower for keyword in ['ä¾›åº”å•†']):
            return 'supplier_name'
        
        return None
    
    def _extract_from_row(self, row: pd.Series, row_index: int, file_path: str) -> Tuple[List[ExtractedEntity], List[ExtractedRelation]]:
        """ä»å•è¡Œæ•°æ®æŠ½å–å®ä½“å’Œå…³ç³»"""
        entities = []
        relations = []
        
        # ç”Ÿæˆå¼‚å¸¸å®ä½“çš„å”¯ä¸€é”®
        anomaly_key = self._generate_anomaly_key(row, row_index)
        
        # æŠ½å–å·¥å‚å®ä½“
        if 'factory_name' in row and pd.notna(row['factory_name']):
            factory_entity = self._extract_factory(row['factory_name'])
            entities.append(factory_entity)
            
            # åˆ›å»º HAPPENED_IN å…³ç³»
            relations.append(ExtractedRelation(
                source_key=anomaly_key,
                target_key=factory_entity.key,
                relation_type='HAPPENED_IN'
            ))
        
        # æŠ½å–é¡¹ç›®å®ä½“
        if 'project_name' in row and pd.notna(row['project_name']):
            project_entity = self._extract_project(row)
            entities.append(project_entity)
            
            # åˆ›å»º RELATED_TO å…³ç³»
            relations.append(ExtractedRelation(
                source_key=anomaly_key,
                target_key=project_entity.key,
                relation_type='RELATED_TO'
            ))
        
        # æŠ½å–ç‰©æ–™å®ä½“
        if ('material_code' in row and pd.notna(row['material_code'])) or \
           ('material_desc' in row and pd.notna(row['material_desc'])):
            material_entity = self._extract_material(row)
            entities.append(material_entity)
            
            # åˆ›å»º INVOLVES å…³ç³»
            relations.append(ExtractedRelation(
                source_key=anomaly_key,
                target_key=material_entity.key,
                relation_type='INVOLVES'
            ))
            
            # æŠ½å–ä¾›åº”å•†å®ä½“ï¼ˆå¦‚æœæœ‰ï¼‰
            if 'supplier_name' in row and pd.notna(row['supplier_name']):
                supplier_entity = self._extract_supplier(row['supplier_name'])
                entities.append(supplier_entity)
                
                # åˆ›å»º SUPPLIED_BY å…³ç³»
                relations.append(ExtractedRelation(
                    source_key=material_entity.key,
                    target_key=supplier_entity.key,
                    relation_type='SUPPLIED_BY'
                ))
        
        # æŠ½å–å¼‚å¸¸å®ä½“
        anomaly_entity = self._extract_anomaly(row, anomaly_key)
        entities.append(anomaly_entity)
        
        # æŠ½å–ç—‡çŠ¶å®ä½“
        symptoms = self._extract_symptoms(row)
        for symptom in symptoms:
            entities.append(symptom)
            relations.append(ExtractedRelation(
                source_key=anomaly_key,
                target_key=symptom.key,
                relation_type='HAS_SYMPTOM'
            ))
        
        # æŠ½å–æ ¹å› å®ä½“
        if 'root_cause' in row and pd.notna(row['root_cause']):
            root_cause_entity = self._extract_root_cause(row['root_cause'])
            entities.append(root_cause_entity)
            
            # åˆ›å»º HAS_ROOTCAUSE å…³ç³»
            relations.append(ExtractedRelation(
                source_key=anomaly_key,
                target_key=root_cause_entity.key,
                relation_type='HAS_ROOTCAUSE'
            ))
            
            # æŠ½å–å¯¹ç­–å®ä½“
            countermeasures = self._extract_countermeasures(row)
            for countermeasure in countermeasures:
                entities.append(countermeasure)
                relations.append(ExtractedRelation(
                    source_key=root_cause_entity.key,
                    target_key=countermeasure.key,
                    relation_type='RESOLVED_BY'
                ))
        
        # æŠ½å–è´£ä»»äººå®ä½“
        if 'owner_name' in row and pd.notna(row['owner_name']):
            owner_entity = self._extract_owner(row['owner_name'])
            entities.append(owner_entity)
            
            # åˆ›å»º OWNED_BY å…³ç³»
            relations.append(ExtractedRelation(
                source_key=anomaly_key,
                target_key=owner_entity.key,
                relation_type='OWNED_BY'
            ))
        
        # æŠ½å–æ–‡æ¡£å®ä½“
        doc_entity = self._extract_document(file_path)
        entities.append(doc_entity)
        
        # åˆ›å»º DOCUMENTED_IN å…³ç³»
        relations.append(ExtractedRelation(
            source_key=anomaly_key,
            target_key=doc_entity.key,
            relation_type='DOCUMENTED_IN'
        ))
        
        return entities, relations
    
    def _generate_anomaly_key(self, row: pd.Series, row_index: int) -> str:
        """ç”Ÿæˆå¼‚å¸¸å®ä½“çš„å”¯ä¸€é”®"""
        # å°è¯•ä»å¤šä¸ªå­—æ®µç”Ÿæˆé”®
        if 'factory_name' in row and 'anomaly_date' in row and 'material_code' in row:
            factory = str(row['factory_name'])[:10] if pd.notna(row['factory_name']) else 'UNK'
            date = str(row['anomaly_date'])[:10] if pd.notna(row['anomaly_date']) else 'UNK'
            material = str(row['material_code']) if pd.notna(row['material_code']) else 'UNK'
            return f"Anomaly:{factory}-{date}-{material}"
        else:
            # ä½¿ç”¨è¡Œç´¢å¼•ä½œä¸ºåå¤‡æ–¹æ¡ˆ
            return f"Anomaly:ROW-{row_index:04d}"
    
    def _extract_factory(self, factory_name: str) -> ExtractedEntity:
        """æŠ½å–å·¥å‚å®ä½“"""
        return ExtractedEntity(
            key=f"Factory:{factory_name}",
            type="Factory",
            name=factory_name,
            properties={
                'location': 'ä¸­å›½'  # é»˜è®¤å€¼ï¼Œå¯ä»¥åç»­æ‰©å±•
            }
        )
    
    def _extract_project(self, row: pd.Series) -> ExtractedEntity:
        """æŠ½å–é¡¹ç›®å®ä½“"""
        project_name = str(row['project_name'])
        properties = {}
        
        if 'project_phase' in row and pd.notna(row['project_phase']):
            properties['phase'] = str(row['project_phase'])
        
        return ExtractedEntity(
            key=f"Project:{project_name}",
            type="Project",
            name=project_name,
            properties=properties
        )
    
    def _extract_material(self, row: pd.Series) -> ExtractedEntity:
        """æŠ½å–ç‰©æ–™å®ä½“"""
        if 'material_code' in row and pd.notna(row['material_code']):
            material_key = str(row['material_code'])
        else:
            material_key = str(row.get('material_desc', 'UNKNOWN'))[:20]
        
        properties = {}
        if 'material_code' in row and pd.notna(row['material_code']):
            properties['code'] = str(row['material_code'])
        if 'material_desc' in row and pd.notna(row['material_desc']):
            properties['desc'] = str(row['material_desc'])
        if 'material_category' in row and pd.notna(row['material_category']):
            properties['category'] = str(row['material_category'])
        
        return ExtractedEntity(
            key=f"Material:{material_key}",
            type="Material",
            name=properties.get('desc', material_key),
            properties=properties
        )
    
    def _extract_anomaly(self, row: pd.Series, anomaly_key: str) -> ExtractedEntity:
        """æŠ½å–å¼‚å¸¸å®ä½“"""
        properties = {}
        
        if 'anomaly_title' in row and pd.notna(row['anomaly_title']):
            properties['title'] = str(row['anomaly_title'])
        if 'defects_number' in row and pd.notna(row['defects_number']):
            properties['defects_number'] = int(row['defects_number'])
        if 'defect_rate' in row and pd.notna(row['defect_rate']):
            properties['defect_rate'] = float(row['defect_rate'])
        if 'anomaly_date' in row and pd.notna(row['anomaly_date']):
            properties['date'] = str(row['anomaly_date'])
        if 'anomaly_position' in row and pd.notna(row['anomaly_position']):
            properties['position'] = str(row['anomaly_position'])
        if 'severity' in row and pd.notna(row['severity']):
            properties['severity'] = str(row['severity'])
        
        return ExtractedEntity(
            key=anomaly_key,
            type="Anomaly",
            name=properties.get('title', anomaly_key),
            properties=properties
        )
    
    def _extract_symptoms(self, row: pd.Series) -> List[ExtractedEntity]:
        """æŠ½å–ç—‡çŠ¶å®ä½“"""
        symptoms = []
        
        # ä»å¼‚å¸¸æè¿°ä¸­æŠ½å–ç—‡çŠ¶
        if 'anomaly_title' in row and pd.notna(row['anomaly_title']):
            title = str(row['anomaly_title'])
            
            # ä½¿ç”¨æ¨¡å¼åŒ¹é…æŠ½å–ç—‡çŠ¶
            for pattern_list in self.entity_patterns['Symptom']:
                matches = re.findall(pattern_list, title, re.IGNORECASE)
                for match in matches:
                    symptom = ExtractedEntity(
                        key=f"Symptom:{match}",
                        type="Symptom",
                        name=match,
                        properties={'category': self._categorize_symptom(match)}
                    )
                    symptoms.append(symptom)
        
        return symptoms
    
    def _extract_root_cause(self, root_cause_text: str) -> ExtractedEntity:
        """æŠ½å–æ ¹å› å®ä½“"""
        return ExtractedEntity(
            key=f"RootCause:{root_cause_text}",
            type="RootCause",
            name=root_cause_text,
            properties={
                'detail': root_cause_text,
                'probability': 0.8  # é»˜è®¤æ¦‚ç‡
            }
        )
    
    def _extract_countermeasures(self, row: pd.Series) -> List[ExtractedEntity]:
        """æŠ½å–å¯¹ç­–å®ä½“"""
        countermeasures = []
        
        # æ£€æŸ¥ä¸åŒç±»å‹çš„å¯¹ç­–å­—æ®µ
        countermeasure_fields = [
            ('temp_countermeasure', 'ä¸´æ—¶æªæ–½'),
            ('tech_countermeasure', 'æŠ€æœ¯æªæ–½'),
            ('mgmt_countermeasure', 'ç®¡ç†æªæ–½'),
            ('countermeasure', 'å¯¹ç­–')
        ]
        
        for field, cm_type in countermeasure_fields:
            if field in row and pd.notna(row[field]):
                cm_text = str(row[field])
                countermeasure = ExtractedEntity(
                    key=f"Countermeasure:{cm_text}",
                    type="Countermeasure",
                    name=cm_text,
                    properties={
                        'type': cm_type,
                        'effectiveness': 0.8  # é»˜è®¤æœ‰æ•ˆæ€§
                    }
                )
                countermeasures.append(countermeasure)
        
        return countermeasures
    
    def _extract_owner(self, owner_name: str) -> ExtractedEntity:
        """æŠ½å–è´£ä»»äººå®ä½“"""
        return ExtractedEntity(
            key=f"Owner:{owner_name}",
            type="Owner",
            name=owner_name,
            properties={'role': 'è´¨é‡å·¥ç¨‹å¸ˆ'}  # é»˜è®¤è§’è‰²
        )
    
    def _extract_supplier(self, supplier_name: str) -> ExtractedEntity:
        """æŠ½å–ä¾›åº”å•†å®ä½“"""
        return ExtractedEntity(
            key=f"Supplier:{supplier_name}",
            type="Supplier",
            name=supplier_name,
            properties={}
        )
    
    def _extract_document(self, file_path: str) -> ExtractedEntity:
        """æŠ½å–æ–‡æ¡£å®ä½“"""
        file_name = Path(file_path).name
        return ExtractedEntity(
            key=f"Doc:{file_name}",
            type="Doc",
            name=file_name,
            properties={
                'title': file_name,
                'path': file_path,
                'type': 'Excel',
                'date': datetime.now().strftime('%Y-%m-%d')
            }
        )
    
    def _categorize_symptom(self, symptom: str) -> str:
        """ç—‡çŠ¶åˆ†ç±»"""
        if any(keyword in symptom for keyword in ['è£‚çº¹', 'ç ´æŸ', 'å˜å½¢', 'åˆ’ä¼¤']):
            return 'å¤–è§‚ç¼ºé™·'
        elif any(keyword in symptom for keyword in ['å¤±æ•ˆ', 'æ•…éšœ', 'å¼‚å¸¸']):
            return 'åŠŸèƒ½å¼‚å¸¸'
        elif any(keyword in symptom for keyword in ['ä¸è¾¾æ ‡', 'åå·®']):
            return 'æ€§èƒ½ä¸è¾¾æ ‡'
        else:
            return 'å…¶ä»–'
    
    def _deduplicate_entities(self, entities: List[ExtractedEntity]) -> List[ExtractedEntity]:
        """å®ä½“å»é‡"""
        seen_keys = set()
        unique_entities = []
        
        for entity in entities:
            if entity.key not in seen_keys:
                seen_keys.add(entity.key)
                unique_entities.append(entity)
        
        return unique_entities
    
    def _deduplicate_relations(self, relations: List[ExtractedRelation]) -> List[ExtractedRelation]:
        """å…³ç³»å»é‡"""
        seen_relations = set()
        unique_relations = []
        
        for relation in relations:
            relation_tuple = (relation.source_key, relation.target_key, relation.relation_type)
            if relation_tuple not in seen_relations:
                seen_relations.add(relation_tuple)
                unique_relations.append(relation)
        
        return unique_relations

def main():
    """ä¸»å‡½æ•° - æµ‹è¯•æŠ½å–å™¨"""
    extractor = MaterialAnomalyExtractor()
    
    # æµ‹è¯•æ–‡ä»¶
    test_file = "data/import/æ¥æ–™é—®é¢˜å…ˆåç‰ˆ.xlsx"
    
    if Path(test_file).exists():
        result = extractor.extract_from_excel(test_file)
        
        # ä¿å­˜ç»“æœ
        output_file = "data/processed/material_anomaly_extracted.json"
        Path(output_file).parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… æ¥æ–™å¼‚å¸¸æ•°æ®æŠ½å–å®Œæˆ!")
        print(f"ğŸ“Š æŠ½å–ç»“æœ: {result['metadata']['entity_count']} ä¸ªå®ä½“, {result['metadata']['relation_count']} ä¸ªå…³ç³»")
        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    else:
        print(f"âŒ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")

if __name__ == "__main__":
    main()
