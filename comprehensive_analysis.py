#!/usr/bin/env python3
"""
è¯å…¸åˆ†ç±»å’Œå›¾è°±è®¾è®¡å…¨é¢è¯„ä¼°åˆ†æ
"""
import json
from collections import defaultdict, Counter

# åŠ è½½è¯å…¸æ•°æ®
with open('api/data/dictionary.json', 'r', encoding='utf-8') as f:
    dictionary = json.load(f)

print("=" * 80)
print("ğŸ“Š è¯å…¸åˆ†ç±»å’Œå›¾è°±è®¾è®¡å…¨é¢è¯„ä¼°æŠ¥å‘Š")
print("=" * 80)

# 1. åŸºç¡€ç»Ÿè®¡
print("\n1ï¸âƒ£ åŸºç¡€ç»Ÿè®¡")
print("-" * 80)
print(f"æ€»è¯æ¡æ•°: {len(dictionary)}")

# åˆ†ç±»ç»Ÿè®¡
category_stats = Counter(entry['category'] for entry in dictionary)
print(f"\nåˆ†ç±»åˆ†å¸ƒ (8ç±»):")
for category, count in category_stats.most_common():
    percentage = count / len(dictionary) * 100
    print(f"  {category:20s}: {count:4d} æ¡ ({percentage:5.1f}%)")

# 2. æ ‡ç­¾ä½“ç³»åˆ†æ
print("\n2ï¸âƒ£ æ ‡ç­¾ä½“ç³»åˆ†æ")
print("-" * 80)

all_tags = []
for entry in dictionary:
    all_tags.extend(entry.get('tags', []))

tag_stats = Counter(all_tags)
print(f"æ ‡ç­¾æ€»æ•°: {len(tag_stats)} ä¸ª")
print(f"æ ‡ç­¾ä½¿ç”¨æ€»æ¬¡æ•°: {len(all_tags)} æ¬¡")
print(f"å¹³å‡æ¯è¯æ¡æ ‡ç­¾æ•°: {len(all_tags) / len(dictionary):.2f} ä¸ª")

print(f"\nTop 20 é«˜é¢‘æ ‡ç­¾:")
for tag, count in tag_stats.most_common(20):
    percentage = count / len(dictionary) * 100
    print(f"  {tag:20s}: {count:4d} æ¬¡ ({percentage:5.1f}%)")

# 3. åˆ«åè¦†ç›–ç‡åˆ†æ
print("\n3ï¸âƒ£ åˆ«åè¦†ç›–ç‡åˆ†æ")
print("-" * 80)

entries_with_aliases = sum(1 for entry in dictionary if entry.get('aliases'))
total_aliases = sum(len(entry.get('aliases', [])) for entry in dictionary)
avg_aliases = total_aliases / len(dictionary)

print(f"æœ‰åˆ«åçš„è¯æ¡: {entries_with_aliases} / {len(dictionary)} ({entries_with_aliases/len(dictionary)*100:.1f}%)")
print(f"åˆ«åæ€»æ•°: {total_aliases}")
print(f"å¹³å‡æ¯è¯æ¡åˆ«åæ•°: {avg_aliases:.2f} ä¸ª")

# 4. æè¿°å®Œæ•´åº¦åˆ†æ
print("\n4ï¸âƒ£ æè¿°å®Œæ•´åº¦åˆ†æ")
print("-" * 80)

entries_with_desc = sum(1 for entry in dictionary if entry.get('description'))
desc_lengths = [len(entry.get('description', '')) for entry in dictionary if entry.get('description')]
avg_desc_length = sum(desc_lengths) / len(desc_lengths) if desc_lengths else 0

print(f"æœ‰æè¿°çš„è¯æ¡: {entries_with_desc} / {len(dictionary)} ({entries_with_desc/len(dictionary)*100:.1f}%)")
print(f"å¹³å‡æè¿°é•¿åº¦: {avg_desc_length:.1f} å­—ç¬¦")

# 5. é¢†åŸŸè¦†ç›–åˆ†æ
print("\n5ï¸âƒ£ é¢†åŸŸè¦†ç›–åˆ†æï¼ˆåŸºäºæ ‡ç­¾ï¼‰")
print("-" * 80)

domain_tags = {
    'å½±åƒç›¸å…³': 0,
    'æ˜¾ç¤ºç›¸å…³': 0,
    'å°„é¢‘ç›¸å…³': 0,
    'é€šä¿¡ç›¸å…³': 0,
    'å£°å­¦': 0,
    'çƒ­ç®¡ç†': 0,
    'EMC': 0,
    'ç»“æ„ç›¸å…³': 0,
    'ç”µæ°”æ€§èƒ½': 0,
    'è½¯ä»¶ç›¸å…³': 0,
    'æµ‹è¯•éªŒè¯': 0,
    'åˆ¶é€ å·¥è‰º': 0,
    'è´¨é‡ä½“ç³»': 0,
}

for tag, count in tag_stats.items():
    for domain in domain_tags:
        if domain in tag:
            domain_tags[domain] += count
            break

print("é¢†åŸŸæ ‡ç­¾ä½¿ç”¨ç»Ÿè®¡:")
for domain, count in sorted(domain_tags.items(), key=lambda x: x[1], reverse=True):
    if count > 0:
        print(f"  {domain:20s}: {count:4d} æ¬¡")

# 6. åˆ†ç±»-æ ‡ç­¾å…³è”åˆ†æ
print("\n6ï¸âƒ£ åˆ†ç±»-æ ‡ç­¾å…³è”åˆ†æ")
print("-" * 80)

category_tag_map = defaultdict(Counter)
for entry in dictionary:
    category = entry['category']
    for tag in entry.get('tags', []):
        category_tag_map[category][tag] += 1

print("å„åˆ†ç±»çš„Top 5æ ‡ç­¾:")
for category in sorted(category_stats.keys()):
    print(f"\n{category}:")
    for tag, count in category_tag_map[category].most_common(5):
        print(f"  {tag:20s}: {count:3d} æ¬¡")

# 7. æ•°æ®è´¨é‡è¯„åˆ†
print("\n7ï¸âƒ£ æ•°æ®è´¨é‡è¯„åˆ†")
print("-" * 80)

# è®¡ç®—å„é¡¹æŒ‡æ ‡
alias_score = (entries_with_aliases / len(dictionary)) * 100
desc_score = (entries_with_desc / len(dictionary)) * 100
tag_score = min((len(all_tags) / len(dictionary) / 3) * 100, 100)  # ç›®æ ‡å¹³å‡3ä¸ªæ ‡ç­¾
category_balance_score = (1 - (max(category_stats.values()) - min(category_stats.values())) / len(dictionary)) * 100

overall_score = (alias_score + desc_score + tag_score + category_balance_score) / 4

print(f"åˆ«åè¦†ç›–ç‡å¾—åˆ†: {alias_score:.1f}/100")
print(f"æè¿°å®Œæ•´åº¦å¾—åˆ†: {desc_score:.1f}/100")
print(f"æ ‡ç­¾ä¸°å¯Œåº¦å¾—åˆ†: {tag_score:.1f}/100")
print(f"åˆ†ç±»å¹³è¡¡åº¦å¾—åˆ†: {category_balance_score:.1f}/100")
print(f"\nç»¼åˆè´¨é‡å¾—åˆ†: {overall_score:.1f}/100")

# 8. å›¾è°±å…³ç³»æ½œåŠ›åˆ†æ
print("\n8ï¸âƒ£ å›¾è°±å…³ç³»æ½œåŠ›åˆ†æ")
print("-" * 80)

# åˆ†æå¯ä»¥å»ºç«‹çš„å…³ç³»ç±»å‹
symptom_count = category_stats.get('Symptom', 0)
component_count = category_stats.get('Component', 0)
testcase_count = category_stats.get('TestCase', 0)
tool_count = category_stats.get('Tool', 0)
process_count = category_stats.get('Process', 0)

print(f"å½“å‰å…³ç³»æ•°: 3770 (HAS_TAG) + 1333 (BELONGS_TO) = 5103")
print(f"\næ½œåœ¨å…³ç³»æ‰©å±•:")
print(f"  Symptom â†’ Component (AFFECTS): æœ€å¤š {symptom_count * component_count} æ¡")
print(f"  TestCase â†’ Component (TESTS): æœ€å¤š {testcase_count * component_count} æ¡")
print(f"  Tool â†’ TestCase (USED_IN): æœ€å¤š {tool_count * testcase_count} æ¡")
print(f"  Process â†’ Component (PRODUCES): æœ€å¤š {process_count * component_count} æ¡")

# 9. é—®é¢˜è¯†åˆ«
print("\n9ï¸âƒ£ é—®é¢˜è¯†åˆ«")
print("-" * 80)

issues = []

# æ£€æŸ¥ç¼ºå°‘åˆ«åçš„è¯æ¡
no_alias_entries = [e for e in dictionary if not e.get('aliases')]
if no_alias_entries:
    issues.append(f"âš ï¸ {len(no_alias_entries)} æ¡è¯æ¡ç¼ºå°‘åˆ«å")

# æ£€æŸ¥ç¼ºå°‘æè¿°çš„è¯æ¡
no_desc_entries = [e for e in dictionary if not e.get('description')]
if no_desc_entries:
    issues.append(f"âš ï¸ {len(no_desc_entries)} æ¡è¯æ¡ç¼ºå°‘æè¿°")

# æ£€æŸ¥æ ‡ç­¾è¿‡å°‘çš„è¯æ¡
few_tags_entries = [e for e in dictionary if len(e.get('tags', [])) < 2]
if few_tags_entries:
    issues.append(f"âš ï¸ {len(few_tags_entries)} æ¡è¯æ¡æ ‡ç­¾å°‘äº2ä¸ª")

# æ£€æŸ¥åˆ†ç±»ä¸å¹³è¡¡
max_cat = max(category_stats.values())
min_cat = min(category_stats.values())
if max_cat / min_cat > 5:
    issues.append(f"âš ï¸ åˆ†ç±»ä¸å¹³è¡¡: æœ€å¤š{max_cat}æ¡ vs æœ€å°‘{min_cat}æ¡ (å·®è·{max_cat/min_cat:.1f}å€)")

if issues:
    print("å‘ç°çš„é—®é¢˜:")
    for issue in issues:
        print(f"  {issue}")
else:
    print("âœ… æœªå‘ç°æ˜æ˜¾é—®é¢˜")

# 10. ä¼˜åŒ–å»ºè®®
print("\nğŸ”Ÿ ä¼˜åŒ–å»ºè®®")
print("-" * 80)

suggestions = []

# åŸºäºåˆ†æç»™å‡ºå»ºè®®
if alias_score < 95:
    suggestions.append(f"ğŸ“ æå‡åˆ«åè¦†ç›–ç‡: å½“å‰{alias_score:.1f}%ï¼Œå»ºè®®è¡¥å……{len(dictionary) - entries_with_aliases}æ¡è¯æ¡çš„åˆ«å")

if tag_score < 90:
    suggestions.append(f"ğŸ·ï¸ å¢åŠ æ ‡ç­¾ä¸°å¯Œåº¦: å½“å‰å¹³å‡{len(all_tags)/len(dictionary):.2f}ä¸ª/è¯æ¡ï¼Œå»ºè®®å¢è‡³3ä¸ªä»¥ä¸Š")

if category_balance_score < 80:
    suggestions.append(f"âš–ï¸ å¹³è¡¡åˆ†ç±»åˆ†å¸ƒ: è¡¥å……{min(category_stats, key=category_stats.get)}ç±»è¯æ¡")

# é¢†åŸŸè¦†ç›–å»ºè®®
weak_domains = [d for d, c in domain_tags.items() if c < 50]
if weak_domains:
    suggestions.append(f"ğŸ¯ åŠ å¼ºå¼±åŠ¿é¢†åŸŸ: {', '.join(weak_domains[:3])}")

# å…³ç³»å»ºç«‹å»ºè®®
suggestions.append(f"ğŸ”— å»ºç«‹è¯­ä¹‰å…³ç³»: ä¼˜å…ˆå»ºç«‹Symptom-Componentã€TestCase-Componentå…³ç³»")

if suggestions:
    print("ä¼˜åŒ–å»ºè®®:")
    for i, suggestion in enumerate(suggestions, 1):
        print(f"  {i}. {suggestion}")

print("\n" + "=" * 80)
print("âœ… è¯„ä¼°å®Œæˆ")
print("=" * 80)

