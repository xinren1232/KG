#!/usr/bin/env python3
"""
æ–‡æ¡£æ–‡ä»¶åˆ†æå’Œæ•´ç†å·¥å…·
"""
import os
import re
from pathlib import Path
from datetime import datetime

def analyze_documentation():
    """åˆ†ææ‰€æœ‰æ–‡æ¡£æ–‡ä»¶"""
    print("ğŸ“„ æ–‡æ¡£æ–‡ä»¶è¯¦ç»†åˆ†æ")
    print("=" * 60)
    
    doc_files = []
    
    # æŸ¥æ‰¾æ‰€æœ‰æ–‡æ¡£æ–‡ä»¶
    for root, dirs, files in os.walk('.'):
        dirs[:] = [d for d in dirs if d not in ['.git', '__pycache__', 'node_modules', '.venv']]
        
        for file in files:
            if file.endswith('.md'):
                file_path = Path(root) / file
                doc_files.append(file_path)
    
    return doc_files

def categorize_docs(doc_files):
    """åˆ†ç±»æ–‡æ¡£æ–‡ä»¶"""
    categories = {
        'user_docs': [],           # ç”¨æˆ·æ–‡æ¡£
        'technical_docs': [],      # æŠ€æœ¯æ–‡æ¡£
        'progress_reports': [],    # è¿›å±•æŠ¥å‘Š
        'completion_reports': [],  # å®ŒæˆæŠ¥å‘Š
        'fix_reports': [],         # ä¿®å¤æŠ¥å‘Š
        'optimization_reports': [], # ä¼˜åŒ–æŠ¥å‘Š
        'design_docs': [],         # è®¾è®¡æ–‡æ¡£
        'implementation_docs': [], # å®ç°æ–‡æ¡£
        'summary_docs': [],        # æ€»ç»“æ–‡æ¡£
        'outdated_docs': [],       # è¿‡æ—¶æ–‡æ¡£
        'duplicate_docs': [],      # é‡å¤æ–‡æ¡£
        'other_docs': []           # å…¶ä»–æ–‡æ¡£
    }
    
    for doc_file in doc_files:
        file_name = doc_file.name.lower()
        
        # ç”¨æˆ·æ–‡æ¡£
        if any(keyword in file_name for keyword in ['readme', 'ç”¨æˆ·', 'user', 'manual', 'æ‰‹å†Œ']):
            categories['user_docs'].append(doc_file)
        # æŠ€æœ¯æ–‡æ¡£
        elif any(keyword in file_name for keyword in ['technical', 'schema', 'ontology', 'api']):
            categories['technical_docs'].append(doc_file)
        # è¿›å±•æŠ¥å‘Š
        elif any(keyword in file_name for keyword in ['progress', 'è¿›å±•', 'status']):
            categories['progress_reports'].append(doc_file)
        # å®ŒæˆæŠ¥å‘Š
        elif any(keyword in file_name for keyword in ['complete', 'å®Œæˆ', 'final', 'summary']):
            categories['completion_reports'].append(doc_file)
        # ä¿®å¤æŠ¥å‘Š
        elif any(keyword in file_name for keyword in ['fix', 'repair', 'resolution', 'error']):
            categories['fix_reports'].append(doc_file)
        # ä¼˜åŒ–æŠ¥å‘Š
        elif any(keyword in file_name for keyword in ['optimization', 'enhance', 'improve']):
            categories['optimization_reports'].append(doc_file)
        # è®¾è®¡æ–‡æ¡£
        elif any(keyword in file_name for keyword in ['design', 'plan', 'architecture']):
            categories['design_docs'].append(doc_file)
        # å®ç°æ–‡æ¡£
        elif any(keyword in file_name for keyword in ['implementation', 'integration', 'parsing']):
            categories['implementation_docs'].append(doc_file)
        # æ€»ç»“æ–‡æ¡£
        elif any(keyword in file_name for keyword in ['summary', 'æ€»ç»“', 'achievement']):
            categories['summary_docs'].append(doc_file)
        # è¿‡æ—¶æ–‡æ¡£ (åŒ…å«æ—¥æœŸ)
        elif re.search(r'\d{4}|\d{2}_\d{2}|v\d+|old|backup', file_name):
            categories['outdated_docs'].append(doc_file)
        else:
            categories['other_docs'].append(doc_file)
    
    return categories

def analyze_doc_content(file_path):
    """åˆ†ææ–‡æ¡£å†…å®¹"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        lines = content.split('\n')
        non_empty_lines = [line for line in lines if line.strip()]
        
        # æ£€æŸ¥æ–‡æ¡£è´¨é‡
        has_title = content.startswith('#')
        has_structure = content.count('#') > 1
        has_content = len(non_empty_lines) > 10
        
        # æ£€æŸ¥æœ€åä¿®æ”¹æ—¶é—´
        mod_time = datetime.fromtimestamp(file_path.stat().st_mtime)
        days_old = (datetime.now() - mod_time).days
        
        return {
            'total_lines': len(lines),
            'content_lines': len(non_empty_lines),
            'has_title': has_title,
            'has_structure': has_structure,
            'has_content': has_content,
            'days_old': days_old,
            'size_kb': file_path.stat().st_size / 1024
        }
    except Exception as e:
        return {
            'total_lines': 0,
            'content_lines': 0,
            'has_title': False,
            'has_structure': False,
            'has_content': False,
            'days_old': 0,
            'size_kb': 0,
            'error': str(e)
        }

def print_doc_analysis(categories):
    """æ‰“å°æ–‡æ¡£åˆ†æç»“æœ"""
    print("\nğŸ“Š æ–‡æ¡£åˆ†ç±»ç»“æœ:")
    print("-" * 40)
    
    for category, files in categories.items():
        if files:
            category_name = category.replace('_', ' ').title()
            print(f"\n{category_name} ({len(files)} ä¸ª):")
            for file_path in sorted(files):
                info = analyze_doc_content(file_path)
                quality = "ğŸŸ¢" if info['has_content'] and info['has_structure'] else "ğŸŸ¡" if info['has_content'] else "ğŸ”´"
                age = f"{info['days_old']}å¤©å‰" if info['days_old'] > 0 else "ä»Šå¤©"
                print(f"   {quality} {file_path} ({info['content_lines']} è¡Œ, {age})")

def generate_docs_cleanup_plan(categories):
    """ç”Ÿæˆæ–‡æ¡£æ¸…ç†è®¡åˆ’"""
    print(f"\n" + "=" * 60)
    print("ğŸ“„ æ–‡æ¡£æ•´ç†è®¡åˆ’")
    print("=" * 60)
    
    # éœ€è¦ä¿ç•™çš„æ ¸å¿ƒæ–‡æ¡£
    keep_docs = []
    keep_docs.extend(categories['user_docs'])
    keep_docs.extend(categories['technical_docs'])
    keep_docs.extend(categories['design_docs'])
    
    # éœ€è¦åˆå¹¶çš„æŠ¥å‘Šæ–‡æ¡£
    merge_docs = []
    merge_docs.extend(categories['progress_reports'])
    merge_docs.extend(categories['completion_reports'])
    merge_docs.extend(categories['fix_reports'])
    merge_docs.extend(categories['optimization_reports'])
    
    # éœ€è¦åˆ é™¤çš„è¿‡æ—¶æ–‡æ¡£
    delete_docs = []
    delete_docs.extend(categories['outdated_docs'])
    
    # éœ€è¦å½’æ¡£çš„å®ç°æ–‡æ¡£
    archive_docs = []
    archive_docs.extend(categories['implementation_docs'])
    archive_docs.extend(categories['summary_docs'])
    
    print(f"âœ… ä¿ç•™æ ¸å¿ƒæ–‡æ¡£ ({len(keep_docs)} ä¸ª):")
    for doc in sorted(keep_docs):
        print(f"   âœ… {doc}")
    
    print(f"\nğŸ”„ åˆå¹¶æŠ¥å‘Šæ–‡æ¡£ ({len(merge_docs)} ä¸ª):")
    for doc in sorted(merge_docs):
        print(f"   ğŸ”„ {doc}")
    
    print(f"\nğŸ—‘ï¸ åˆ é™¤è¿‡æ—¶æ–‡æ¡£ ({len(delete_docs)} ä¸ª):")
    for doc in sorted(delete_docs):
        print(f"   âŒ {doc}")
    
    print(f"\nğŸ“ å½’æ¡£å®ç°æ–‡æ¡£ ({len(archive_docs)} ä¸ª):")
    for doc in sorted(archive_docs):
        print(f"   ğŸ“ {doc}")
    
    # å»ºè®®çš„æ–‡æ¡£ç»“æ„
    print(f"\nğŸ“‚ å»ºè®®çš„æ–‡æ¡£ç›®å½•ç»“æ„:")
    print("   docs/")
    print("   â”œâ”€â”€ README.md                    # é¡¹ç›®æ¦‚è¿°")
    print("   â”œâ”€â”€ user-guide.md               # ç”¨æˆ·æ‰‹å†Œ")
    print("   â”œâ”€â”€ api-documentation.md        # APIæ–‡æ¡£")
    print("   â”œâ”€â”€ technical/")
    print("   â”‚   â”œâ”€â”€ architecture.md         # ç³»ç»Ÿæ¶æ„")
    print("   â”‚   â”œâ”€â”€ database-schema.md      # æ•°æ®åº“è®¾è®¡")
    print("   â”‚   â””â”€â”€ deployment.md           # éƒ¨ç½²æŒ‡å—")
    print("   â”œâ”€â”€ development/")
    print("   â”‚   â”œâ”€â”€ setup.md                # å¼€å‘ç¯å¢ƒ")
    print("   â”‚   â”œâ”€â”€ contributing.md         # è´¡çŒ®æŒ‡å—")
    print("   â”‚   â””â”€â”€ testing.md              # æµ‹è¯•æŒ‡å—")
    print("   â””â”€â”€ archive/")
    print("       â”œâ”€â”€ project-reports/        # é¡¹ç›®æŠ¥å‘Šå½’æ¡£")
    print("       â””â”€â”€ implementation-logs/    # å®ç°è®°å½•å½’æ¡£")
    
    return keep_docs, merge_docs, delete_docs, archive_docs

def main():
    """ä¸»å‡½æ•°"""
    doc_files = analyze_documentation()
    print(f"å‘ç° {len(doc_files)} ä¸ªæ–‡æ¡£æ–‡ä»¶")
    
    categories = categorize_docs(doc_files)
    print_doc_analysis(categories)
    
    keep_docs, merge_docs, delete_docs, archive_docs = generate_docs_cleanup_plan(categories)
    
    print(f"\n" + "=" * 60)
    print("ğŸ“‹ æ–‡æ¡£åˆ†æå®Œæˆ")
    print(f"æ€»è®¡: {len(doc_files)} ä¸ªæ–‡æ¡£")
    print(f"ä¿ç•™æ ¸å¿ƒ: {len(keep_docs)} ä¸ª")
    print(f"åˆå¹¶æŠ¥å‘Š: {len(merge_docs)} ä¸ª")
    print(f"åˆ é™¤è¿‡æ—¶: {len(delete_docs)} ä¸ª")
    print(f"å½’æ¡£å®ç°: {len(archive_docs)} ä¸ª")
    print("=" * 60)
    
    return categories, keep_docs, merge_docs, delete_docs, archive_docs

if __name__ == "__main__":
    main()
