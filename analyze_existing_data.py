#!/usr/bin/env python3
"""
åˆ†æç°æœ‰è¯å…¸æ•°æ®ï¼Œæå–è®¾è®¡è§„èŒƒå’Œè´¨é‡æ ‡å‡†
"""
import json
from collections import Counter, defaultdict

def analyze_existing_dictionary():
    """åˆ†æç°æœ‰è¯å…¸çš„è®¾è®¡è§„èŒƒ"""
    print("=" * 80)
    print("ğŸ“š ç°æœ‰è¯å…¸æ•°æ®åˆ†æ - æå–è®¾è®¡è§„èŒƒ")
    print("=" * 80)
    
    with open('api/data/dictionary.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"\næ€»æ¡ç›®æ•°: {len(data)}")
    
    # 1. åˆ†æå­—æ®µç»“æ„
    print(f"\nğŸ“‹ å­—æ®µç»“æ„åˆ†æ:")
    if data:
        sample = data[0]
        print(f"æ ‡å‡†å­—æ®µ: {list(sample.keys())}")
        for key, value in sample.items():
            print(f"  - {key}: {type(value).__name__} = {str(value)[:60]}...")
    
    # 2. åˆ†æåˆ†ç±»åˆ†å¸ƒ
    print(f"\nğŸ“‚ åˆ†ç±»(category)åˆ†å¸ƒ:")
    categories = Counter(e.get('category', 'Unknown') for e in data)
    for cat, count in categories.most_common():
        print(f"  {cat}: {count}æ¡")
    
    # 3. åˆ†ææ ‡ç­¾ä½¿ç”¨
    print(f"\nğŸ·ï¸ æ ‡ç­¾(tags)ä½¿ç”¨åˆ†æ:")
    all_tags = []
    for entry in data:
        tags = entry.get('tags', [])
        if isinstance(tags, list):
            all_tags.extend(tags)
    tag_counts = Counter(all_tags)
    print(f"  æ€»æ ‡ç­¾æ•°: {len(tag_counts)}")
    print(f"  Top 20æ ‡ç­¾:")
    for tag, count in tag_counts.most_common(20):
        print(f"    - {tag}: {count}æ¬¡")
    
    # 4. åˆ†ææ‘„åƒå¤´ç›¸å…³æ•°æ®
    print(f"\nğŸ“· æ‘„åƒå¤´ç›¸å…³æ•°æ®åˆ†æ:")
    camera_keywords = ['æ‘„åƒå¤´', 'Camera', 'å¯¹ç„¦', 'é•œå¤´', 'Lens', 'å½±åƒ', 'VCM', 'ISP', 'OIS']
    camera_entries = []
    for entry in data:
        term = entry.get('term', '')
        desc = entry.get('description', '')
        tags = ' '.join(entry.get('tags', []))
        combined = f"{term} {desc} {tags}"
        if any(kw in combined for kw in camera_keywords):
            camera_entries.append(entry)
    
    print(f"  æ‘„åƒå¤´ç›¸å…³æ¡ç›®: {len(camera_entries)}æ¡")
    
    # æŒ‰åˆ†ç±»ç»Ÿè®¡
    camera_by_category = defaultdict(list)
    for entry in camera_entries:
        camera_by_category[entry.get('category', 'Unknown')].append(entry)
    
    print(f"  åˆ†ç±»åˆ†å¸ƒ:")
    for cat, entries in sorted(camera_by_category.items(), key=lambda x: len(x[1]), reverse=True):
        print(f"    {cat}: {len(entries)}æ¡")
    
    # æ˜¾ç¤ºç¤ºä¾‹
    print(f"\n  Componentç±»ç¤ºä¾‹ (å‰3æ¡):")
    for i, entry in enumerate([e for e in camera_entries if e.get('category')=='Component'][:3], 1):
        print(f"    {i}. {entry.get('term')}")
        print(f"       åˆ«å: {', '.join(entry.get('aliases', [])[:3])}")
        print(f"       æ ‡ç­¾: {', '.join(entry.get('tags', [])[:3])}")
        print(f"       æè¿°: {entry.get('description', '')[:80]}...")
    
    print(f"\n  Symptomç±»ç¤ºä¾‹ (å‰3æ¡):")
    for i, entry in enumerate([e for e in camera_entries if e.get('category')=='Symptom'][:3], 1):
        print(f"    {i}. {entry.get('term')}")
        print(f"       åˆ«å: {', '.join(entry.get('aliases', [])[:3])}")
        print(f"       æ ‡ç­¾: {', '.join(entry.get('tags', [])[:3])}")
        desc = entry.get('description', '')
        if '**å®šä¹‰**' in desc:
            print(f"       æè¿°: [ç»“æ„åŒ–æè¿°]")
        else:
            print(f"       æè¿°: {desc[:80]}...")
    
    # 5. åˆ†ææè¿°æ ¼å¼
    print(f"\nğŸ“ æè¿°(description)æ ¼å¼åˆ†æ:")
    structured_count = 0
    simple_count = 0
    for entry in data:
        desc = entry.get('description', '')
        if '**å®šä¹‰**' in desc or '**åˆ¤å®šå£å¾„**' in desc:
            structured_count += 1
        else:
            simple_count += 1
    
    print(f"  ç»“æ„åŒ–æè¿°: {structured_count}æ¡ ({structured_count/len(data)*100:.1f}%)")
    print(f"  ç®€å•æè¿°: {simple_count}æ¡ ({simple_count/len(data)*100:.1f}%)")
    
    # æ˜¾ç¤ºç»“æ„åŒ–æè¿°ç¤ºä¾‹
    structured_examples = [e for e in data if '**å®šä¹‰**' in e.get('description', '')]
    if structured_examples:
        print(f"\n  ç»“æ„åŒ–æè¿°ç¤ºä¾‹:")
        example = structured_examples[0]
        print(f"    æœ¯è¯­: {example.get('term')}")
        print(f"    æè¿°: {example.get('description', '')[:200]}...")
    
    # 6. åˆ†æåˆ«åæ ¼å¼
    print(f"\nğŸ”¤ åˆ«å(aliases)æ ¼å¼åˆ†æ:")
    alias_counts = [len(e.get('aliases', [])) for e in data]
    avg_aliases = sum(alias_counts) / len(alias_counts) if alias_counts else 0
    print(f"  å¹³å‡åˆ«åæ•°: {avg_aliases:.1f}")
    print(f"  æœ€å¤šåˆ«åæ•°: {max(alias_counts)}")
    
    # æ˜¾ç¤ºåˆ«åä¸°å¯Œçš„ç¤ºä¾‹
    rich_alias_entries = sorted(data, key=lambda x: len(x.get('aliases', [])), reverse=True)[:3]
    print(f"\n  åˆ«åä¸°å¯Œç¤ºä¾‹:")
    for i, entry in enumerate(rich_alias_entries, 1):
        print(f"    {i}. {entry.get('term')}: {len(entry.get('aliases', []))}ä¸ªåˆ«å")
        print(f"       {', '.join(entry.get('aliases', [])[:5])}")
    
    # 7. åˆ†æMaterialç±»æ•°æ®
    print(f"\nğŸ§ª Materialç±»æ•°æ®åˆ†æ:")
    materials = [e for e in data if e.get('category') == 'Material']
    print(f"  Materialæ¡ç›®: {len(materials)}æ¡")
    
    if materials:
        print(f"\n  Materialæ ‡ç­¾åˆ†å¸ƒ:")
        material_tags = []
        for m in materials:
            material_tags.extend(m.get('tags', []))
        material_tag_counts = Counter(material_tags)
        for tag, count in material_tag_counts.most_common(10):
            print(f"    - {tag}: {count}æ¬¡")
        
        print(f"\n  Materialç¤ºä¾‹ (å‰3æ¡):")
        for i, entry in enumerate(materials[:3], 1):
            print(f"    {i}. {entry.get('term')}")
            print(f"       åˆ«å: {', '.join(entry.get('aliases', [])[:2])}")
            print(f"       æ ‡ç­¾: {', '.join(entry.get('tags', [])[:3])}")
            print(f"       æè¿°: {entry.get('description', '')[:60]}...")
    
    # 8. æå–è®¾è®¡è§„èŒƒ
    print(f"\n" + "=" * 80)
    print("ğŸ“ æå–çš„è®¾è®¡è§„èŒƒæ€»ç»“")
    print("=" * 80)
    
    print(f"\n1. å­—æ®µç»“æ„:")
    print(f"   å¿…å¡«å­—æ®µ: term, aliases, category, tags, description")
    print(f"   å¯é€‰å­—æ®µ: sub_category, source, status, original_category")
    
    print(f"\n2. åˆ†ç±»(category)è§„èŒƒ:")
    print(f"   æ ‡å‡†åˆ†ç±»: {', '.join(categories.keys())}")
    
    print(f"\n3. æ ‡ç­¾(tags)è§„èŒƒ:")
    print(f"   - ä½¿ç”¨æ•°ç»„æ ¼å¼")
    print(f"   - å¹³å‡æ¯æ¡{sum(len(e.get('tags',[])) for e in data)/len(data):.1f}ä¸ªæ ‡ç­¾")
    print(f"   - å¸¸ç”¨æ ‡ç­¾: ç¡¬ä»¶ç›¸å…³ã€æµ‹è¯•éªŒè¯ã€å¯é æ€§ã€åˆ¶é€ å·¥è‰ºç­‰")
    
    print(f"\n4. æè¿°(description)è§„èŒƒ:")
    print(f"   - ç®€å•æè¿°: ä¸€å¥è¯è¯´æ˜æœ¯è¯­å«ä¹‰å’Œåº”ç”¨åœºæ™¯")
    print(f"   - ç»“æ„åŒ–æè¿°: åŒ…å«å®šä¹‰ã€åˆ¤å®šå£å¾„ã€å¸¸è§åœºæ™¯ã€æ’æŸ¥è·¯å¾„ã€å¯¹ç­–")
    print(f"   - æ¨èSymptomç±»ä½¿ç”¨ç»“æ„åŒ–æè¿°")
    
    print(f"\n5. åˆ«å(aliases)è§„èŒƒ:")
    print(f"   - ä½¿ç”¨æ•°ç»„æ ¼å¼")
    print(f"   - åŒ…å«ä¸­æ–‡åˆ«åã€è‹±æ–‡å…¨ç§°ã€è‹±æ–‡ç¼©å†™")
    print(f"   - å¹³å‡æ¯æ¡{avg_aliases:.1f}ä¸ªåˆ«å")
    
    print(f"\n6. æ‘„åƒå¤´é¢†åŸŸè§„èŒƒ:")
    print(f"   - Componentç±»: ç¡¬ä»¶ç»„ä»¶ï¼Œæ ‡ç­¾åŒ…å«'å½±åƒç›¸å…³'ã€'æ‘„åƒå¤´æ¨¡ç»„'")
    print(f"   - Symptomç±»: å¼‚å¸¸ç°è±¡ï¼Œæ ‡ç­¾åŒ…å«'å½±åƒç›¸å…³'ã€'æ‘„åƒå¤´æ¨¡ç»„'ã€'å¼‚å¸¸ç°è±¡'")
    print(f"   - TestCaseç±»: æµ‹è¯•æ–¹æ³•ï¼Œæ ‡ç­¾åŒ…å«'æµ‹è¯•éªŒè¯'ã€'å½±åƒç›¸å…³'")
    print(f"   - Processç±»: å·¥è‰ºæµç¨‹ï¼Œæ ‡ç­¾åŒ…å«'åˆ¶é€ å·¥è‰º'ã€'å½±åƒç›¸å…³'")
    
    print(f"\n7. Materialç±»è§„èŒƒ:")
    print(f"   - æ ‡ç­¾å¿…å«'ç‰©æ–™'")
    print(f"   - å¸¸ç”¨æ ‡ç­¾: EMCã€çƒ­ç®¡ç†ã€æ˜¾ç¤ºç›¸å…³ã€ç‚¹èƒ¶ã€ç»“æ„ç›¸å…³ç­‰")
    print(f"   - æè¿°æ ¼å¼: è¯´æ˜ææ–™ç”¨é€”å’Œç‰¹æ€§")

if __name__ == "__main__":
    analyze_existing_dictionary()
