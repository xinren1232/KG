# å›¾è°±ä¼˜åŒ–å®æ–½è®¡åˆ’

åŸºäºå¯è¡Œæ€§è¯„ä¼°ï¼Œåˆ¶å®šè¯¦ç»†çš„åˆ†é˜¶æ®µå®æ–½è®¡åˆ’ã€‚

---

## ğŸ“… æ€»ä½“æ—¶é—´è¡¨

```
ç¬¬ä¸€é˜¶æ®µ (Week 1-2): åŸºç¡€è®¾æ–½å»ºè®¾
ç¬¬äºŒé˜¶æ®µ (Week 3-4): æ ¸å¿ƒå…³ç³»è¡¥å……  
ç¬¬ä¸‰é˜¶æ®µ (Week 5-6): æŸ¥è¯¢ä¸åº”ç”¨é›†æˆ
```

---

## ğŸ¯ ç¬¬ä¸€é˜¶æ®µ: åŸºç¡€è®¾æ–½å»ºè®¾ (Week 1-2)

### Day 1: ç´¢å¼•ä¸çº¦æŸ

**ä»»åŠ¡æ¸…å•**:
- [ ] åˆ›å»ºå”¯ä¸€çº¦æŸ
- [ ] åˆ›å»ºå±æ€§ç´¢å¼•
- [ ] åˆ›å»ºå…¨æ–‡ç´¢å¼•
- [ ] éªŒè¯ç´¢å¼•æ•ˆæœ

**å®æ–½è„šæœ¬**:
```cypher
// 1. å”¯ä¸€çº¦æŸ
CREATE CONSTRAINT term_uq IF NOT EXISTS
FOR (t:Term) REQUIRE (t.name, t.category) IS UNIQUE;

// 2. å±æ€§ç´¢å¼•
CREATE INDEX term_category IF NOT EXISTS 
FOR (t:Term) ON (t.category);

CREATE INDEX term_name IF NOT EXISTS 
FOR (t:Term) ON (t.name);

// 3. å…¨æ–‡ç´¢å¼•ï¼ˆæ”¯æŒä¸­æ–‡ï¼‰
CREATE FULLTEXT INDEX term_fulltext IF NOT EXISTS
FOR (t:Term) ON EACH [t.name, t.description];

// 4. å…³ç³»å±æ€§ç´¢å¼•
CREATE INDEX rel_confidence IF NOT EXISTS
FOR ()-[r:CAUSES]-() ON (r.confidence);

CREATE INDEX rel_status IF NOT EXISTS
FOR ()-[r]-() ON (r.status);

// 5. éªŒè¯
SHOW CONSTRAINTS;
SHOW INDEXES;
```

**éªŒè¯æ ‡å‡†**:
- âœ… æ‰€æœ‰çº¦æŸåˆ›å»ºæˆåŠŸ
- âœ… æ‰€æœ‰ç´¢å¼•åˆ›å»ºæˆåŠŸ
- âœ… æŸ¥è¯¢æ€§èƒ½æå‡ï¼ˆEXPLAINåˆ†æï¼‰

---

### Day 2-3: å…³ç³»å±æ€§æ ‡å‡†åŒ–

**ä»»åŠ¡æ¸…å•**:
- [ ] ä¸ºç°æœ‰CAUSESå…³ç³»è¡¥å……å±æ€§
- [ ] ä¸ºå…¶ä»–å…³ç³»è¡¥å……å±æ€§
- [ ] éªŒè¯å±æ€§å®Œæ•´æ€§

**å®æ–½è„šæœ¬**:
```cypher
// 1. ä¸ºCAUSESå…³ç³»è¡¥å……source_hash
MATCH ()-[r:CAUSES]->()
WHERE r.source_hash IS NULL
WITH r, 
     apoc.util.md5([r.evidence, r.source, toString(r.created_at)]) AS hash
SET r.source_hash = hash,
    r.status = 'verified',
    r.updated_at = datetime()
RETURN count(*) as updated;

// 2. ä¸ºå…¶ä»–å…³ç³»è¡¥å……åŸºç¡€å±æ€§
MATCH ()-[r:AFFECTS|TESTS|USED_IN|PRODUCES|RELATED_TO]->()
WHERE r.status IS NULL
SET r.status = 'verified',
    r.confidence = 0.8,
    r.source = 'legacy_data',
    r.created_at = coalesce(r.created_at, datetime()),
    r.updated_at = datetime()
RETURN type(r) as rel_type, count(*) as updated;

// 3. éªŒè¯
MATCH ()-[r]->()
WHERE r.status IS NOT NULL
RETURN type(r) as rel_type, 
       count(*) as total,
       avg(r.confidence) as avg_conf
ORDER BY total DESC;
```

**éªŒè¯æ ‡å‡†**:
- âœ… æ‰€æœ‰ä¸šåŠ¡å…³ç³»éƒ½æœ‰statuså±æ€§
- âœ… æ‰€æœ‰CAUSESå…³ç³»éƒ½æœ‰source_hash
- âœ… å¹³å‡confidence >= 0.7

---

### Day 4-5: ETLæ ¡éªŒå™¨å¼€å‘

**ä»»åŠ¡æ¸…å•**:
- [ ] åˆ›å»ºPydanticæ¨¡å‹
- [ ] å®ç°æ ¡éªŒé€»è¾‘
- [ ] æ·»åŠ APIç«¯ç‚¹
- [ ] å•å…ƒæµ‹è¯•

**ä»£ç å®ç°**:
```python
# api/models/relation_input.py
from pydantic import BaseModel, Field, validator
from typing import Literal, Optional
from datetime import datetime

class NodeRef(BaseModel):
    """èŠ‚ç‚¹å¼•ç”¨"""
    name: str = Field(..., min_length=1, max_length=200)
    category: Literal['Symptom', 'RootCause', 'Solution', 'Component', 
                      'TestCase', 'Metric', 'Tool', 'Material', 'Process', 'Role']

class RelationProps(BaseModel):
    """å…³ç³»å±æ€§"""
    confidence: float = Field(..., ge=0.1, le=1.0)
    evidence: str = Field(..., min_length=10, max_length=500)
    source: str = Field(default='manual')
    doc_id: Optional[str] = None
    chunk_id: Optional[str] = None
    status: Literal['verified', 'plausible', 'uncertain'] = 'plausible'
    
    # ç‰¹æœ‰å±æ€§
    severity: Optional[Literal['P0', 'P1', 'P2', 'P3']] = None
    phase: Optional[Literal['EVT', 'DVT', 'PVT', 'MP', 'Field']] = None
    effectiveness: Optional[float] = Field(None, ge=0.0, le=1.0)
    risk: Optional[Literal['low', 'mid', 'high']] = None
    cost_level: Optional[Literal['L', 'M', 'H']] = None
    
    @validator('confidence')
    def check_confidence(cls, v):
        if v < 0.6:
            # ä½ç½®ä¿¡åº¦è‡ªåŠ¨æ ‡è®°ä¸ºplausible
            return v
        return v

class RelationInput(BaseModel):
    """å…³ç³»è¾“å…¥"""
    relation_type: Literal['CAUSES', 'RESOLVED_BY', 'PREVENTS', 
                           'DEPENDS_ON', 'DETECTS', 'TESTS', 'MEASURES', 'AFFECTS']
    source: NodeRef
    target: NodeRef
    props: RelationProps
    
    @validator('relation_type')
    def validate_relation_type(cls, v, values):
        """éªŒè¯å…³ç³»ç±»å‹ä¸èŠ‚ç‚¹ç±»å‹çš„åŒ¹é…"""
        valid_combinations = {
            'CAUSES': [('Symptom', 'Symptom'), ('RootCause', 'Symptom')],
            'RESOLVED_BY': [('Symptom', 'Solution')],
            'PREVENTS': [('Solution', 'Symptom')],
            'DEPENDS_ON': [('Component', 'Component'), ('Component', 'Material'), 
                          ('Component', 'Tool')],
            'DETECTS': [('TestCase', 'Symptom')],
            'TESTS': [('TestCase', 'Component'), ('TestCase', 'Process')],
            'MEASURES': [('TestCase', 'Metric')],
            'AFFECTS': [('Component', 'Symptom')],
        }
        
        if 'source' in values and 'target' in values:
            source_cat = values['source'].category
            target_cat = values['target'].category
            
            if v in valid_combinations:
                if (source_cat, target_cat) not in valid_combinations[v]:
                    raise ValueError(
                        f'{v} relation requires {valid_combinations[v]}, '
                        f'got ({source_cat}, {target_cat})'
                    )
        
        return v

class RelationBatch(BaseModel):
    """æ‰¹é‡å…³ç³»è¾“å…¥"""
    relations: list[RelationInput] = Field(..., min_items=1, max_items=100)


# api/main.py æ·»åŠ ç«¯ç‚¹
@app.post("/kg/relations/validate")
async def validate_relations(batch: RelationBatch):
    """éªŒè¯å…³ç³»æ•°æ®"""
    return {
        "ok": True,
        "data": {
            "valid_count": len(batch.relations),
            "relations": [r.dict() for r in batch.relations]
        }
    }

@app.post("/kg/relations/import")
async def import_relations(batch: RelationBatch):
    """å¯¼å…¥å…³ç³»æ•°æ®"""
    # å®ç°å¯¼å…¥é€»è¾‘
    pass
```

**éªŒè¯æ ‡å‡†**:
- âœ… æ ¡éªŒå™¨èƒ½æ­£ç¡®éªŒè¯å…³ç³»ç±»å‹
- âœ… æ ¡éªŒå™¨èƒ½æ£€æµ‹èŠ‚ç‚¹ç±»å‹ä¸åŒ¹é…
- âœ… ä½ç½®ä¿¡åº¦(<0.6)è‡ªåŠ¨æ ‡è®°ä¸ºplausible
- âœ… APIç«¯ç‚¹æ­£å¸¸å·¥ä½œ

---

### Day 6-7: å…³ç³»Upsertæ¨¡æ¿

**ä»»åŠ¡æ¸…å•**:
- [ ] å®ç°é€šç”¨Upsertå‡½æ•°
- [ ] æ”¯æŒå»é‡ï¼ˆsource_hashï¼‰
- [ ] æ”¯æŒå†²çªæ£€æµ‹
- [ ] æ€§èƒ½æµ‹è¯•

**å®æ–½è„šæœ¬**:
```python
# api/services/kg_service.py
from neo4j import GraphDatabase
import hashlib
from datetime import datetime

class KGService:
    def __init__(self, driver):
        self.driver = driver
    
    def upsert_relation(self, relation_input: RelationInput):
        """é€šç”¨å…³ç³»Upsert"""
        with self.driver.session() as session:
            return session.execute_write(
                self._upsert_relation_tx,
                relation_input
            )
    
    def _upsert_relation_tx(self, tx, rel_input):
        """Upsertäº‹åŠ¡"""
        # 1. è®¡ç®—merge_key
        source_key = f"{rel_input.source.name}:{rel_input.source.category}"
        target_key = f"{rel_input.target.name}:{rel_input.target.category}"
        evidence = rel_input.props.evidence
        
        source_hash = hashlib.md5(
            f"{source_key}|{target_key}|{evidence}".encode()
        ).hexdigest()
        
        # 2. Upsertå…³ç³»
        query = f"""
        MATCH (s:Term {{name: $source_name, category: $source_category}})
        MATCH (t:Term {{name: $target_name, category: $target_category}})
        WITH s, t, $props AS props, $source_hash AS merge_key
        MERGE (s)-[rel:{rel_input.relation_type} {{merge_key: merge_key}}]->(t)
        ON CREATE SET 
            rel += props,
            rel.source_hash = merge_key,
            rel.created_at = datetime(),
            rel.updated_at = datetime()
        ON MATCH SET
            rel.confidence = CASE 
                WHEN props.confidence > rel.confidence 
                THEN props.confidence 
                ELSE rel.confidence 
            END,
            rel.evidence = props.evidence,
            rel.status = props.status,
            rel.updated_at = datetime()
        RETURN rel, 
               CASE WHEN rel.created_at = rel.updated_at THEN 'created' ELSE 'updated' END as action
        """
        
        result = tx.run(
            query,
            source_name=rel_input.source.name,
            source_category=rel_input.source.category,
            target_name=rel_input.target.name,
            target_category=rel_input.target.category,
            props=rel_input.props.dict(exclude_none=True),
            source_hash=source_hash
        )
        
        record = result.single()
        return {
            "action": record["action"],
            "relation": dict(record["rel"])
        }
```

**éªŒè¯æ ‡å‡†**:
- âœ… ç›¸åŒsource_hashçš„å…³ç³»ä¸é‡å¤åˆ›å»º
- âœ… æ›´æ–°æ—¶ä¿ç•™æ›´é«˜çš„confidence
- âœ… æ€§èƒ½: å•æ¡æ’å…¥ < 50ms

---

## ğŸ¯ ç¬¬äºŒé˜¶æ®µ: æ ¸å¿ƒå…³ç³»è¡¥å…… (Week 3-4)

### Week 3: RESOLVED_BYå…³ç³»

**ç›®æ ‡**: è¡¥å……100+æ¡è§£å†³æ–¹æ¡ˆå…³ç³»

**æ•°æ®æ¥æº**:
1. ç°æœ‰æ¡ˆä¾‹æ–‡æ¡£ä¸­çš„è§£å†³æ–¹æ¡ˆ
2. è´¨é‡æ”¹è¿›è®°å½•
3. ä¸“å®¶çŸ¥è¯†

**å®æ–½æ­¥éª¤**:
```python
# 1. ä»æ¡ˆä¾‹æ–‡æ¡£æŠ½å–
# ç¤ºä¾‹æ•°æ®
resolved_by_relations = [
    {
        "source": {"name": "ç”µæ± ç›–è£‚çº¹", "category": "Symptom"},
        "target": {"name": "æ›´æ¢æ²»å…·å¹¶æ¸…æ´", "category": "Solution"},
        "props": {
            "confidence": 0.9,
            "evidence": "æ›´æ¢æ²»å…·åï¼Œè£‚çº¹ä¸è‰¯ç‡ä»5%é™è‡³0.1%",
            "effectiveness": 0.95,
            "risk": "low",
            "cost_level": "M"
        }
    },
    # ... æ›´å¤šå…³ç³»
]

# 2. æ‰¹é‡å¯¼å…¥
for rel in resolved_by_relations:
    kg_service.upsert_relation(RelationInput(
        relation_type='RESOLVED_BY',
        **rel
    ))
```

**éªŒè¯æ ‡å‡†**:
- âœ… å¯¼å…¥100+æ¡RESOLVED_BYå…³ç³»
- âœ… å¹³å‡effectiveness >= 0.7
- âœ… æ‰€æœ‰å…³ç³»éƒ½æœ‰evidence

---

### Week 4: PREVENTSå’ŒDEPENDS_ONå…³ç³»

**PREVENTSå…³ç³»ç›®æ ‡**: 50+æ¡

**DEPENDS_ONå…³ç³»ç›®æ ‡**: 200+æ¡

**å®æ–½æ–¹æ³•**: åŒRESOLVED_BY

---

## ğŸ¯ ç¬¬ä¸‰é˜¶æ®µ: æŸ¥è¯¢ä¸åº”ç”¨ (Week 5-6)

### Week 5: æŸ¥è¯¢APIå¼€å‘

**å®æ–½APIç«¯ç‚¹**:
```python
@app.get("/kg/diagnose")
async def diagnose_symptom(symptom: str, min_conf: float = 0.7):
    """æ•…éšœè¯Šæ–­"""
    query = """
    MATCH (s:Term {name: $symptom, category: 'Symptom'})
          -[r:CAUSES]->(rc:Term)
    WHERE r.confidence >= $min_conf
    OPTIONAL MATCH (s)-[res:RESOLVED_BY]->(sol:Term)
    RETURN s, r, rc, res, sol
    ORDER BY r.confidence DESC, coalesce(res.effectiveness, 0) DESC
    LIMIT 50
    """
    # æ‰§è¡ŒæŸ¥è¯¢...

@app.get("/kg/prevent")
async def get_prevention(symptom: str):
    """é¢„é˜²å»ºè®®"""
    # å®ç°...

@app.get("/kg/test-path")
async def get_test_path(symptom: str):
    """æµ‹è¯•è·¯å¾„"""
    # å®ç°...

@app.get("/kg/dependencies")
async def get_dependencies(component: str):
    """ç»„ä»¶ä¾èµ–"""
    # å®ç°...
```

---

### Week 6: è´¨é‡çœ‹æ¿ä¸Difyé›†æˆ

**è´¨é‡çœ‹æ¿æŒ‡æ ‡**:
1. å…³ç³»ç±»å‹åˆ†å¸ƒ
2. ä½ç½®ä¿¡åº¦å æ¯”
3. å®Œæ•´é“¾è¦†ç›–ç‡
4. æŸ¥è¯¢æ€§èƒ½

**Difyé›†æˆ**:
- ChatFlowå¹¶è¡Œè°ƒç”¨RAG+KG
- æç¤ºè¯èåˆ
- A/Bæµ‹è¯•

---

## ğŸ“Š æˆåŠŸæ ‡å‡†

### æ•°æ®æŒ‡æ ‡
- âœ… RESOLVED_BYå…³ç³» >= 100æ¡
- âœ… PREVENTSå…³ç³» >= 50æ¡
- âœ… DEPENDS_ONå…³ç³» >= 200æ¡
- âœ… å¹³å‡confidence >= 0.75
- âœ… ä½ç½®ä¿¡åº¦(<0.7)å æ¯” < 20%

### æ€§èƒ½æŒ‡æ ‡
- âœ… æŸ¥è¯¢95p < 300ms
- âœ… å¯¼å…¥æ€§èƒ½ > 20æ¡/ç§’

### ä¸šåŠ¡æŒ‡æ ‡
- âœ… è¯Šæ–­å‡†ç¡®ç‡ > 80%
- âœ… ç”¨æˆ·æ»¡æ„åº¦ > 4.0/5.0

---

**åˆ¶å®šæ—¶é—´**: 2025-10-09  
**é¢„è®¡å®Œæˆ**: 2025-11-20 (6å‘¨)  
**è´Ÿè´£äºº**: å¼€å‘å›¢é˜Ÿ
