#!/usr/bin/env python3
"""
è¯å…¸æ•°æ®å¯è§†åŒ–åˆ†æ
ç”Ÿæˆè¯å…¸ç³»ç»Ÿçš„æ•°æ®åˆ†æå›¾è¡¨å’Œç»Ÿè®¡æŠ¥å‘Š
"""

import json
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter, defaultdict
import numpy as np
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False

def load_dictionary_data():
    """åŠ è½½è¯å…¸æ•°æ®"""
    print("ğŸ“Š åŠ è½½è¯å…¸æ•°æ®...")
    
    try:
        with open('api/data/dictionary.json', 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"  âœ… æˆåŠŸåŠ è½½ {len(data)} æ¡è¯å…¸æ•°æ®")
        return data
    except Exception as e:
        print(f"  âŒ åŠ è½½å¤±è´¥: {e}")
        return []

def analyze_category_distribution(data):
    """åˆ†æåˆ†ç±»åˆ†å¸ƒ"""
    print("ğŸ“Š åˆ†æåˆ†ç±»åˆ†å¸ƒ...")
    
    categories = [item.get('category', 'Unknown') for item in data]
    category_counts = Counter(categories)
    
    # åˆ›å»ºåˆ†ç±»åˆ†å¸ƒå›¾
    plt.figure(figsize=(12, 8))
    
    # é¥¼å›¾
    plt.subplot(2, 2, 1)
    colors = plt.cm.Set3(np.linspace(0, 1, len(category_counts)))
    wedges, texts, autotexts = plt.pie(category_counts.values(), 
                                       labels=category_counts.keys(),
                                       autopct='%1.1f%%',
                                       colors=colors,
                                       startangle=90)
    plt.title('è¯å…¸åˆ†ç±»åˆ†å¸ƒ (é¥¼å›¾)', fontsize=14, fontweight='bold')
    
    # æŸ±çŠ¶å›¾
    plt.subplot(2, 2, 2)
    bars = plt.bar(category_counts.keys(), category_counts.values(), 
                   color=colors[:len(category_counts)])
    plt.title('è¯å…¸åˆ†ç±»åˆ†å¸ƒ (æŸ±çŠ¶å›¾)', fontsize=14, fontweight='bold')
    plt.xlabel('åˆ†ç±»')
    plt.ylabel('æ•°é‡')
    plt.xticks(rotation=45)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar in bars:
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height + 1,
                f'{int(height)}', ha='center', va='bottom')
    
    # æ°´å¹³æŸ±çŠ¶å›¾
    plt.subplot(2, 2, 3)
    y_pos = np.arange(len(category_counts))
    plt.barh(y_pos, list(category_counts.values()), color=colors[:len(category_counts)])
    plt.yticks(y_pos, list(category_counts.keys()))
    plt.xlabel('æ•°é‡')
    plt.title('è¯å…¸åˆ†ç±»åˆ†å¸ƒ (æ°´å¹³)', fontsize=14, fontweight='bold')
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, v in enumerate(category_counts.values()):
        plt.text(v + 5, i, str(v), va='center')
    
    # ç´¯ç§¯åˆ†å¸ƒ
    plt.subplot(2, 2, 4)
    sorted_categories = sorted(category_counts.items(), key=lambda x: x[1], reverse=True)
    cumulative = np.cumsum([count for _, count in sorted_categories])
    plt.plot(range(len(cumulative)), cumulative, 'o-', linewidth=2, markersize=8)
    plt.xlabel('åˆ†ç±»æ’å')
    plt.ylabel('ç´¯ç§¯æ•°é‡')
    plt.title('åˆ†ç±»ç´¯ç§¯åˆ†å¸ƒ', fontsize=14, fontweight='bold')
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('è¯å…¸åˆ†ç±»åˆ†å¸ƒåˆ†æ.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    return category_counts

def analyze_tag_distribution(data):
    """åˆ†ææ ‡ç­¾åˆ†å¸ƒ"""
    print("ğŸ“Š åˆ†ææ ‡ç­¾åˆ†å¸ƒ...")
    
    all_tags = []
    for item in data:
        tags = item.get('tags', [])
        if isinstance(tags, list):
            all_tags.extend(tags)
        elif isinstance(tags, str):
            all_tags.extend([tag.strip() for tag in tags.split(',') if tag.strip()])
    
    tag_counts = Counter(all_tags)
    top_20_tags = dict(tag_counts.most_common(20))
    
    # åˆ›å»ºæ ‡ç­¾åˆ†å¸ƒå›¾
    plt.figure(figsize=(15, 10))
    
    # TOP 20æ ‡ç­¾æŸ±çŠ¶å›¾
    plt.subplot(2, 2, 1)
    bars = plt.bar(range(len(top_20_tags)), list(top_20_tags.values()), 
                   color=plt.cm.viridis(np.linspace(0, 1, len(top_20_tags))))
    plt.title('TOP 20 æ ‡ç­¾ä½¿ç”¨é¢‘ç‡', fontsize=14, fontweight='bold')
    plt.xlabel('æ ‡ç­¾')
    plt.ylabel('ä½¿ç”¨æ¬¡æ•°')
    plt.xticks(range(len(top_20_tags)), list(top_20_tags.keys()), rotation=45, ha='right')
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, bar in enumerate(bars):
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                f'{int(height)}', ha='center', va='bottom', fontsize=8)
    
    # æ ‡ç­¾ä½¿ç”¨åˆ†å¸ƒç›´æ–¹å›¾
    plt.subplot(2, 2, 2)
    usage_counts = list(tag_counts.values())
    plt.hist(usage_counts, bins=20, color='skyblue', alpha=0.7, edgecolor='black')
    plt.title('æ ‡ç­¾ä½¿ç”¨é¢‘ç‡åˆ†å¸ƒ', fontsize=14, fontweight='bold')
    plt.xlabel('ä½¿ç”¨æ¬¡æ•°')
    plt.ylabel('æ ‡ç­¾æ•°é‡')
    plt.grid(True, alpha=0.3)
    
    # æ ‡ç­¾é•¿åº¦åˆ†å¸ƒ
    plt.subplot(2, 2, 3)
    tag_lengths = [len(tag) for tag in tag_counts.keys()]
    plt.hist(tag_lengths, bins=15, color='lightcoral', alpha=0.7, edgecolor='black')
    plt.title('æ ‡ç­¾é•¿åº¦åˆ†å¸ƒ', fontsize=14, fontweight='bold')
    plt.xlabel('æ ‡ç­¾é•¿åº¦ (å­—ç¬¦æ•°)')
    plt.ylabel('æ ‡ç­¾æ•°é‡')
    plt.grid(True, alpha=0.3)
    
    # æ ‡ç­¾ä½¿ç”¨ç‡åˆ†æ
    plt.subplot(2, 2, 4)
    total_items = len(data)
    usage_rates = [(count/total_items)*100 for count in tag_counts.values()]
    plt.scatter(range(len(usage_rates)), sorted(usage_rates, reverse=True), 
               alpha=0.6, s=30, c=range(len(usage_rates)), cmap='plasma')
    plt.title('æ ‡ç­¾ä½¿ç”¨ç‡åˆ†å¸ƒ', fontsize=14, fontweight='bold')
    plt.xlabel('æ ‡ç­¾æ’å')
    plt.ylabel('ä½¿ç”¨ç‡ (%)')
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('è¯å…¸æ ‡ç­¾åˆ†å¸ƒåˆ†æ.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    return tag_counts

def analyze_data_quality(data):
    """åˆ†ææ•°æ®è´¨é‡"""
    print("ğŸ“Š åˆ†ææ•°æ®è´¨é‡...")
    
    total_items = len(data)
    quality_metrics = {}
    
    # å­—æ®µå®Œæ•´æ€§åˆ†æ
    fields = ['term', 'aliases', 'category', 'tags', 'description']
    completeness = {}
    
    for field in fields:
        non_empty_count = 0
        for item in data:
            value = item.get(field)
            if value:
                if isinstance(value, list) and len(value) > 0:
                    non_empty_count += 1
                elif isinstance(value, str) and value.strip():
                    non_empty_count += 1
        
        completeness[field] = (non_empty_count / total_items) * 100
    
    # åˆ›å»ºæ•°æ®è´¨é‡å›¾è¡¨
    plt.figure(figsize=(15, 10))
    
    # å­—æ®µå®Œæ•´æ€§
    plt.subplot(2, 3, 1)
    bars = plt.bar(completeness.keys(), completeness.values(), 
                   color=['green' if v >= 90 else 'orange' if v >= 70 else 'red' for v in completeness.values()])
    plt.title('å­—æ®µå®Œæ•´æ€§åˆ†æ', fontsize=14, fontweight='bold')
    plt.ylabel('å®Œæ•´ç‡ (%)')
    plt.xticks(rotation=45)
    plt.ylim(0, 100)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar in bars:
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height + 1,
                f'{height:.1f}%', ha='center', va='bottom')
    
    # åˆ«åæ•°é‡åˆ†å¸ƒ
    plt.subplot(2, 3, 2)
    alias_counts = []
    for item in data:
        aliases = item.get('aliases', [])
        if isinstance(aliases, list):
            alias_counts.append(len(aliases))
        else:
            alias_counts.append(0)
    
    plt.hist(alias_counts, bins=10, color='lightblue', alpha=0.7, edgecolor='black')
    plt.title('åˆ«åæ•°é‡åˆ†å¸ƒ', fontsize=14, fontweight='bold')
    plt.xlabel('åˆ«åæ•°é‡')
    plt.ylabel('è¯æ¡æ•°é‡')
    plt.grid(True, alpha=0.3)
    
    # æ ‡ç­¾æ•°é‡åˆ†å¸ƒ
    plt.subplot(2, 3, 3)
    tag_counts_per_item = []
    for item in data:
        tags = item.get('tags', [])
        if isinstance(tags, list):
            tag_counts_per_item.append(len(tags))
        else:
            tag_counts_per_item.append(0)
    
    plt.hist(tag_counts_per_item, bins=10, color='lightgreen', alpha=0.7, edgecolor='black')
    plt.title('æ¯æ¡è¯å…¸çš„æ ‡ç­¾æ•°é‡åˆ†å¸ƒ', fontsize=14, fontweight='bold')
    plt.xlabel('æ ‡ç­¾æ•°é‡')
    plt.ylabel('è¯æ¡æ•°é‡')
    plt.grid(True, alpha=0.3)
    
    # æè¿°é•¿åº¦åˆ†å¸ƒ
    plt.subplot(2, 3, 4)
    description_lengths = []
    for item in data:
        desc = item.get('description', '')
        if isinstance(desc, str):
            description_lengths.append(len(desc))
        else:
            description_lengths.append(0)
    
    plt.hist(description_lengths, bins=20, color='lightyellow', alpha=0.7, edgecolor='black')
    plt.title('æè¿°é•¿åº¦åˆ†å¸ƒ', fontsize=14, fontweight='bold')
    plt.xlabel('æè¿°é•¿åº¦ (å­—ç¬¦æ•°)')
    plt.ylabel('è¯æ¡æ•°é‡')
    plt.grid(True, alpha=0.3)
    
    # æœ¯è¯­é•¿åº¦åˆ†å¸ƒ
    plt.subplot(2, 3, 5)
    term_lengths = []
    for item in data:
        term = item.get('term', '')
        if isinstance(term, str):
            term_lengths.append(len(term))
        else:
            term_lengths.append(0)
    
    plt.hist(term_lengths, bins=15, color='lightpink', alpha=0.7, edgecolor='black')
    plt.title('æœ¯è¯­é•¿åº¦åˆ†å¸ƒ', fontsize=14, fontweight='bold')
    plt.xlabel('æœ¯è¯­é•¿åº¦ (å­—ç¬¦æ•°)')
    plt.ylabel('è¯æ¡æ•°é‡')
    plt.grid(True, alpha=0.3)
    
    # è´¨é‡è¯„åˆ†é›·è¾¾å›¾
    plt.subplot(2, 3, 6)
    categories = list(completeness.keys())
    values = list(completeness.values())
    
    # è®¡ç®—è§’åº¦
    angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()
    values += values[:1]  # é—­åˆå›¾å½¢
    angles += angles[:1]
    
    ax = plt.subplot(2, 3, 6, projection='polar')
    ax.plot(angles, values, 'o-', linewidth=2, color='blue')
    ax.fill(angles, values, alpha=0.25, color='blue')
    ax.set_xticks(angles[:-1])
    ax.set_xticklabels(categories)
    ax.set_ylim(0, 100)
    ax.set_title('æ•°æ®è´¨é‡é›·è¾¾å›¾', fontsize=14, fontweight='bold', pad=20)
    
    plt.tight_layout()
    plt.savefig('è¯å…¸æ•°æ®è´¨é‡åˆ†æ.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    return completeness

def generate_summary_report(data, category_counts, tag_counts, completeness):
    """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
    print("ğŸ“Š ç”Ÿæˆæ€»ç»“æŠ¥å‘Š...")
    
    total_items = len(data)
    total_categories = len(category_counts)
    total_tags = len(tag_counts)
    
    # è®¡ç®—å¹³å‡å€¼
    avg_aliases = np.mean([len(item.get('aliases', [])) if isinstance(item.get('aliases', []), list) else 0 for item in data])
    avg_tags = np.mean([len(item.get('tags', [])) if isinstance(item.get('tags', []), list) else 0 for item in data])
    avg_description_length = np.mean([len(item.get('description', '')) if isinstance(item.get('description', ''), str) else 0 for item in data])
    
    # ç”ŸæˆæŠ¥å‘Š
    report = f"""
# ğŸ“Š è¯å…¸æ•°æ®åˆ†ææ€»ç»“æŠ¥å‘Š

## ğŸ¯ æ•°æ®æ¦‚è§ˆ
- **æ€»è¯æ¡æ•°**: {total_items:,} æ¡
- **åˆ†ç±»æ•°é‡**: {total_categories} ä¸ª
- **æ ‡ç­¾æ•°é‡**: {total_tags} ä¸ª
- **ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“Š åˆ†ç±»åˆ†å¸ƒ
"""
    
    for category, count in category_counts.most_common():
        percentage = (count / total_items) * 100
        report += f"- **{category}**: {count} æ¡ ({percentage:.1f}%)\n"
    
    report += f"""
## ğŸ·ï¸ æ ‡ç­¾ä½¿ç”¨æƒ…å†µ
- **æœ€å¸¸ç”¨æ ‡ç­¾**: {tag_counts.most_common(1)[0][0]} ({tag_counts.most_common(1)[0][1]} æ¬¡)
- **æ ‡ç­¾ä½¿ç”¨æ€»æ¬¡æ•°**: {sum(tag_counts.values())} æ¬¡
- **å¹³å‡æ¯æ¡è¯å…¸æ ‡ç­¾æ•°**: {avg_tags:.1f} ä¸ª

### TOP 10 æ ‡ç­¾
"""
    
    for tag, count in tag_counts.most_common(10):
        usage_rate = (count / total_items) * 100
        report += f"- **{tag}**: {count} æ¬¡ ({usage_rate:.1f}%)\n"
    
    report += f"""
## ğŸ“ˆ æ•°æ®è´¨é‡æŒ‡æ ‡
- **å¹³å‡åˆ«åæ•°**: {avg_aliases:.1f} ä¸ª
- **å¹³å‡æè¿°é•¿åº¦**: {avg_description_length:.0f} å­—ç¬¦

### å­—æ®µå®Œæ•´æ€§
"""
    
    for field, completeness_rate in completeness.items():
        status = "ä¼˜ç§€" if completeness_rate >= 90 else "è‰¯å¥½" if completeness_rate >= 70 else "éœ€æ”¹è¿›"
        report += f"- **{field}**: {completeness_rate:.1f}% ({status})\n"
    
    report += f"""
## ğŸ¯ å…³é”®å‘ç°
1. **æ•°æ®è§„æ¨¡**: å…± {total_items:,} æ¡è¯å…¸æ•°æ®ï¼Œè§„æ¨¡è¾ƒå¤§
2. **åˆ†ç±»å‡è¡¡**: {category_counts.most_common(1)[0][0]} ç±»åˆ«å æ¯”æœ€é«˜ ({(category_counts.most_common(1)[0][1]/total_items)*100:.1f}%)
3. **æ ‡ç­¾ä¸°å¯Œ**: å…±ä½¿ç”¨ {total_tags} ä¸ªä¸åŒæ ‡ç­¾ï¼Œæ ‡ç­¾ä½“ç³»å®Œæ•´
4. **è´¨é‡æ°´å¹³**: æ•´ä½“æ•°æ®è´¨é‡è‰¯å¥½ï¼Œæ ¸å¿ƒå­—æ®µå®Œæ•´æ€§é«˜

## ğŸ’¡ æ”¹è¿›å»ºè®®
1. **å¹³è¡¡åˆ†ç±»åˆ†å¸ƒ**: è¡¥å……æ•°é‡è¾ƒå°‘çš„åˆ†ç±»æ•°æ®
2. **ä¼˜åŒ–æ ‡ç­¾ä½¿ç”¨**: æé«˜ä½é¢‘æ ‡ç­¾çš„ä½¿ç”¨ç‡
3. **å®Œå–„æè¿°ä¿¡æ¯**: æé«˜æè¿°å­—æ®µçš„å®Œæ•´æ€§
4. **æ ‡å‡†åŒ–ç®¡ç†**: å»ºç«‹æ›´ä¸¥æ ¼çš„æ•°æ®è´¨é‡æ§åˆ¶æµç¨‹

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
    
    # ä¿å­˜æŠ¥å‘Š
    with open('è¯å…¸æ•°æ®åˆ†ææŠ¥å‘Š.md', 'w', encoding='utf-8') as f:
        f.write(report)
    
    print("  âœ… æŠ¥å‘Šå·²ä¿å­˜: è¯å…¸æ•°æ®åˆ†ææŠ¥å‘Š.md")
    return report

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” è¯å…¸æ•°æ®å¯è§†åŒ–åˆ†æ")
    print("=" * 50)
    
    # åŠ è½½æ•°æ®
    data = load_dictionary_data()
    if not data:
        print("âŒ æ— æ³•åŠ è½½æ•°æ®ï¼Œé€€å‡ºåˆ†æ")
        return
    
    # åˆ†æåˆ†ç±»åˆ†å¸ƒ
    category_counts = analyze_category_distribution(data)
    
    # åˆ†ææ ‡ç­¾åˆ†å¸ƒ
    tag_counts = analyze_tag_distribution(data)
    
    # åˆ†ææ•°æ®è´¨é‡
    completeness = analyze_data_quality(data)
    
    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    report = generate_summary_report(data, category_counts, tag_counts, completeness)
    
    print("\n" + "=" * 50)
    print("ğŸ“Š åˆ†æå®Œæˆï¼ç”Ÿæˆçš„æ–‡ä»¶:")
    print("  ğŸ“ˆ è¯å…¸åˆ†ç±»åˆ†å¸ƒåˆ†æ.png")
    print("  ğŸ·ï¸ è¯å…¸æ ‡ç­¾åˆ†å¸ƒåˆ†æ.png")
    print("  ğŸ“Š è¯å…¸æ•°æ®è´¨é‡åˆ†æ.png")
    print("  ğŸ“‹ è¯å…¸æ•°æ®åˆ†ææŠ¥å‘Š.md")
    print("\nğŸ‰ è¯å…¸æ•°æ®å¯è§†åŒ–åˆ†æå®Œæˆï¼")

if __name__ == "__main__":
    main()
