#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json
import os
from collections import Counter, defaultdict
import re

def analyze_dictionary_data():
    """åˆ†æè¯å…¸æ•°æ®è´¨é‡"""
    print("ğŸ” åˆ†æå½“å‰è¯å…¸æ•°æ®è´¨é‡...")
    
    # è¯»å–è¯å…¸æ•°æ®
    with open('api/data/dictionary.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"ğŸ“Š æ€»æ•°æ®é‡: {len(data)} æ¡")
    
    # æ•°æ®è´¨é‡åˆ†æ
    quality_report = {
        "total_entries": len(data),
        "categories": {},
        "tags": {},
        "data_quality": {
            "complete_entries": 0,
            "missing_description": 0,
            "missing_aliases": 0,
            "missing_tags": 0,
            "duplicate_terms": 0,
            "empty_fields": 0
        },
        "sources": {},
        "modules": {},
        "issues": []
    }
    
    # ç»Ÿè®¡åˆ†ç±»åˆ†å¸ƒ
    categories = Counter()
    tags = Counter()
    sources = Counter()
    terms = []
    
    for entry in data:
        # åˆ†ç±»ç»Ÿè®¡
        category = entry.get('category', 'Unknown')
        categories[category] += 1
        
        # æ ‡ç­¾ç»Ÿè®¡
        entry_tags = entry.get('tags', [])
        if isinstance(entry_tags, list):
            for tag in entry_tags:
                if tag and tag.strip():
                    tags[tag.strip()] += 1
        
        # æ¥æºç»Ÿè®¡
        source = entry.get('source', 'Unknown')
        sources[source] += 1
        
        # æœ¯è¯­æ”¶é›†
        term = entry.get('term', '').strip()
        if term:
            terms.append(term)
        
        # æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
        if all([
            entry.get('term'),
            entry.get('category'),
            entry.get('description'),
            entry.get('tags')
        ]):
            quality_report["data_quality"]["complete_entries"] += 1
        
        if not entry.get('description'):
            quality_report["data_quality"]["missing_description"] += 1
        
        if not entry.get('aliases') or len(entry.get('aliases', [])) == 0:
            quality_report["data_quality"]["missing_aliases"] += 1
        
        if not entry.get('tags') or len(entry.get('tags', [])) == 0:
            quality_report["data_quality"]["missing_tags"] += 1
    
    # é‡å¤æœ¯è¯­æ£€æŸ¥
    term_counts = Counter(terms)
    duplicates = {term: count for term, count in term_counts.items() if count > 1}
    quality_report["data_quality"]["duplicate_terms"] = len(duplicates)
    
    # å¡«å……ç»Ÿè®¡ç»“æœ
    quality_report["categories"] = dict(categories.most_common())
    quality_report["tags"] = dict(tags.most_common(20))  # å‰20ä¸ªæ ‡ç­¾
    quality_report["sources"] = dict(sources)
    
    # è®¡ç®—æ•°æ®è´¨é‡åˆ†æ•°
    total = len(data)
    completeness_score = (quality_report["data_quality"]["complete_entries"] / total) * 100
    uniqueness_score = ((total - quality_report["data_quality"]["duplicate_terms"]) / total) * 100
    coverage_score = ((total - quality_report["data_quality"]["missing_description"]) / total) * 100
    
    overall_quality = (completeness_score + uniqueness_score + coverage_score) / 3
    quality_report["overall_quality_score"] = round(overall_quality, 1)
    
    # ç”Ÿæˆé—®é¢˜åˆ—è¡¨
    issues = []
    if quality_report["data_quality"]["missing_description"] > 0:
        issues.append(f"{quality_report['data_quality']['missing_description']} æ¡è®°å½•ç¼ºå°‘æè¿°")
    
    if quality_report["data_quality"]["missing_aliases"] > total * 0.5:
        issues.append(f"{quality_report['data_quality']['missing_aliases']} æ¡è®°å½•ç¼ºå°‘åˆ«å")
    
    if quality_report["data_quality"]["duplicate_terms"] > 0:
        issues.append(f"å‘ç° {quality_report['data_quality']['duplicate_terms']} ä¸ªé‡å¤æœ¯è¯­")
    
    quality_report["issues"] = issues
    
    return quality_report

def analyze_neo4j_consistency():
    """åˆ†æNeo4jæ•°æ®ä¸€è‡´æ€§"""
    print("\nğŸ” åˆ†æNeo4jæ•°æ®ä¸€è‡´æ€§...")
    
    try:
        from neo4j import GraphDatabase
        driver = GraphDatabase.driver('bolt://localhost:7687', auth=('neo4j', 'password123'))
        
        consistency_report = {
            "neo4j_status": "connected",
            "node_counts": {},
            "relationship_counts": {},
            "orphaned_nodes": 0,
            "consistency_issues": []
        }
        
        with driver.session() as session:
            # èŠ‚ç‚¹ç»Ÿè®¡
            node_result = session.run("""
                CALL db.labels() YIELD label
                CALL {
                    WITH label
                    MATCH (n)
                    WHERE label IN labels(n)
                    RETURN count(n) as count
                }
                RETURN label, count
                ORDER BY count DESC
            """)
            
            for record in node_result:
                consistency_report["node_counts"][record['label']] = record['count']
            
            # å…³ç³»ç»Ÿè®¡
            rel_result = session.run("""
                MATCH ()-[r]->() 
                RETURN type(r) AS type, count(r) AS count 
                ORDER BY count DESC
            """)
            
            for record in rel_result:
                consistency_report["relationship_counts"][record['type']] = record['count']
            
            # æ£€æŸ¥å­¤ç«‹èŠ‚ç‚¹
            orphaned = session.run("""
                MATCH (n:Dictionary)
                WHERE NOT (n)-[]-()
                RETURN count(n) AS count
            """).single()
            
            consistency_report["orphaned_nodes"] = orphaned['count'] if orphaned else 0
            
            # æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§é—®é¢˜
            issues = []
            
            # æ£€æŸ¥æ˜¯å¦æœ‰DictionaryèŠ‚ç‚¹æ²¡æœ‰åˆ†ç±»å…³ç³»
            no_category = session.run("""
                MATCH (d:Dictionary)
                WHERE NOT (d)-[:IN_CATEGORY]->()
                RETURN count(d) AS count
            """).single()
            
            if no_category and no_category['count'] > 0:
                issues.append(f"{no_category['count']} ä¸ªDictionaryèŠ‚ç‚¹ç¼ºå°‘åˆ†ç±»å…³ç³»")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç©ºçš„æ ‡ç­¾èŠ‚ç‚¹
            empty_tags = session.run("""
                MATCH (t:Tag)
                WHERE NOT ()-[:HAS_TAG]->(t)
                RETURN count(t) AS count
            """).single()
            
            if empty_tags and empty_tags['count'] > 0:
                issues.append(f"{empty_tags['count']} ä¸ªTagèŠ‚ç‚¹æ²¡æœ‰è¢«å¼•ç”¨")
            
            consistency_report["consistency_issues"] = issues
        
        driver.close()
        return consistency_report
        
    except Exception as e:
        print(f"âŒ Neo4jè¿æ¥å¤±è´¥: {e}")
        return {
            "neo4j_status": "disconnected",
            "error": str(e)
        }

def generate_governance_config():
    """ç”Ÿæˆæ•°æ®æ²»ç†é…ç½®"""
    print("\nğŸ“‹ ç”Ÿæˆæ•°æ®æ²»ç†é…ç½®...")
    
    # åˆ†ææ•°æ®
    dict_report = analyze_dictionary_data()
    neo4j_report = analyze_neo4j_consistency()
    
    # ç”Ÿæˆæ²»ç†é…ç½®
    governance_config = {
        "timestamp": "2024-01-20 10:00:00",
        "data_overview": {
            "total_entries": dict_report["total_entries"],
            "categories": len(dict_report["categories"]),
            "tags": len(dict_report["tags"]),
            "quality_score": dict_report["overall_quality_score"]
        },
        "quality_metrics": [
            {
                "metric": "æ•°æ®å®Œæ•´æ€§",
                "value": f"{dict_report['data_quality']['complete_entries']}/{dict_report['total_entries']}",
                "percentage": round((dict_report['data_quality']['complete_entries'] / dict_report['total_entries']) * 100, 1),
                "status": "good" if dict_report['data_quality']['complete_entries'] / dict_report['total_entries'] > 0.8 else "warning"
            },
            {
                "metric": "æœ¯è¯­å”¯ä¸€æ€§",
                "value": f"{dict_report['total_entries'] - dict_report['data_quality']['duplicate_terms']}/{dict_report['total_entries']}",
                "percentage": round(((dict_report['total_entries'] - dict_report['data_quality']['duplicate_terms']) / dict_report['total_entries']) * 100, 1),
                "status": "good" if dict_report['data_quality']['duplicate_terms'] == 0 else "warning"
            },
            {
                "metric": "æè¿°è¦†ç›–ç‡",
                "value": f"{dict_report['total_entries'] - dict_report['data_quality']['missing_description']}/{dict_report['total_entries']}",
                "percentage": round(((dict_report['total_entries'] - dict_report['data_quality']['missing_description']) / dict_report['total_entries']) * 100, 1),
                "status": "good"
            },
            {
                "metric": "æ ‡ç­¾è¦†ç›–ç‡",
                "value": f"{dict_report['total_entries'] - dict_report['data_quality']['missing_tags']}/{dict_report['total_entries']}",
                "percentage": round(((dict_report['total_entries'] - dict_report['data_quality']['missing_tags']) / dict_report['total_entries']) * 100, 1),
                "status": "good"
            }
        ],
        "category_distribution": dict_report["categories"],
        "top_tags": dict_report["tags"],
        "data_sources": dict_report["sources"],
        "issues": dict_report["issues"] + neo4j_report.get("consistency_issues", []),
        "neo4j_status": neo4j_report,
        "recommendations": [
            "å®šæœŸæ£€æŸ¥æ•°æ®å®Œæ•´æ€§",
            "å»ºç«‹æ ‡å‡†åŒ–çš„æœ¯è¯­å®¡æ ¸æµç¨‹",
            "å®æ–½è‡ªåŠ¨åŒ–çš„æ•°æ®è´¨é‡ç›‘æ§",
            "å»ºç«‹æ•°æ®å˜æ›´è¿½è¸ªæœºåˆ¶"
        ]
    }
    
    # ä¿å­˜é…ç½®
    with open('config/data_governance_config.json', 'w', encoding='utf-8') as f:
        json.dump(governance_config, f, ensure_ascii=False, indent=2)
    
    print("âœ… æ•°æ®æ²»ç†é…ç½®å·²ç”Ÿæˆ: config/data_governance_config.json")
    
    # æ˜¾ç¤ºæ‘˜è¦
    print(f"\nğŸ“Š æ•°æ®æ²»ç†æ‘˜è¦:")
    print(f"   æ€»æ•°æ®é‡: {dict_report['total_entries']} æ¡")
    print(f"   æ•°æ®è´¨é‡åˆ†: {dict_report['overall_quality_score']}%")
    print(f"   åˆ†ç±»æ•°é‡: {len(dict_report['categories'])} ä¸ª")
    print(f"   æ ‡ç­¾æ•°é‡: {len(dict_report['tags'])} ä¸ª")
    print(f"   å‘ç°é—®é¢˜: {len(governance_config['issues'])} ä¸ª")
    
    return governance_config

if __name__ == "__main__":
    generate_governance_config()
