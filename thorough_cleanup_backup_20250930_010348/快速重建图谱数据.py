#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json
from neo4j import GraphDatabase
from pathlib import Path
from datetime import datetime

class QuickGraphRebuilder:
    def __init__(self, uri="bolt://localhost:7687", user="neo4j", password="password123"):
        self.driver = GraphDatabase.driver(uri, auth=(user, password))
        
    def close(self):
        self.driver.close()
    
    def analyze_current_data(self):
        """åˆ†æå½“å‰æ•°æ®"""
        print("ğŸ” åˆ†æå½“å‰å›¾è°±æ•°æ®")
        print("=" * 50)
        
        with self.driver.session() as session:
            # èŠ‚ç‚¹ç»Ÿè®¡
            node_result = session.run("""
                MATCH (n)
                WHERE n:Component OR n:Symptom OR n:Tool OR n:Process OR n:TestCase OR n:Material OR n:Role OR n:Metric
                RETURN labels(n)[0] as label, count(n) as count
                ORDER BY count DESC
            """)
            
            total_nodes = 0
            print("ğŸ“Š å½“å‰èŠ‚ç‚¹åˆ†å¸ƒ:")
            for record in node_result:
                count = record['count']
                total_nodes += count
                print(f"  {record['label']}: {count} ä¸ª")
            
            # å…³ç³»ç»Ÿè®¡
            rel_result = session.run("""
                MATCH ()-[r]->()
                RETURN type(r) as rel_type, count(r) as count
                ORDER BY count DESC
            """)
            
            total_rels = 0
            print(f"\nğŸ”— å½“å‰å…³ç³»åˆ†å¸ƒ:")
            for record in rel_result:
                count = record['count']
                total_rels += count
                print(f"  {record['rel_type']}: {count} ä¸ª")
            
            print(f"\nğŸ“ˆ å½“å‰æ€»è®¡:")
            print(f"  èŠ‚ç‚¹æ•°: {total_nodes}")
            print(f"  å…³ç³»æ•°: {total_rels}")
            
            return total_nodes, total_rels
    
    def clear_all_data(self):
        """æ¸…ç©ºæ‰€æœ‰æ•°æ®"""
        print("\nğŸ§¹ æ¸…ç©ºæ‰€æœ‰å›¾è°±æ•°æ®")
        print("=" * 50)
        
        with self.driver.session() as session:
            # åˆ é™¤æ‰€æœ‰å…³ç³»
            rel_result = session.run("""
                MATCH ()-[r]->()
                DELETE r
                RETURN count(r) as deleted
            """)
            deleted_rels = rel_result.single()['deleted']
            
            # åˆ é™¤æ‰€æœ‰ç›¸å…³èŠ‚ç‚¹
            node_result = session.run("""
                MATCH (n)
                WHERE n:Component OR n:Symptom OR n:Tool OR n:Process OR n:TestCase OR n:Material OR n:Role OR n:Metric
                DELETE n
                RETURN count(n) as deleted
            """)
            deleted_nodes = node_result.single()['deleted']
            
            print(f"âœ… å·²åˆ é™¤ {deleted_rels} ä¸ªå…³ç³»")
            print(f"âœ… å·²åˆ é™¤ {deleted_nodes} ä¸ªèŠ‚ç‚¹")
            
            return deleted_nodes, deleted_rels
    
    def import_dictionary_data(self):
        """å¯¼å…¥è¯å…¸æ•°æ®"""
        print("\nğŸ“¥ å¯¼å…¥è¯å…¸æ•°æ®")
        print("=" * 50)
        
        # åŠ è½½è¯å…¸æ•°æ®
        dict_file = Path("api/data/dictionary.json")
        if not dict_file.exists():
            print("âŒ è¯å…¸æ–‡ä»¶ä¸å­˜åœ¨")
            return 0, {}
        
        with open(dict_file, 'r', encoding='utf-8') as f:
            dictionary_data = json.load(f)
        
        print(f"ğŸ“š å‡†å¤‡å¯¼å…¥ {len(dictionary_data)} æ¡è¯å…¸æ•°æ®")
        
        imported_count = 0
        category_counts = {}
        
        with self.driver.session() as session:
            for i, item in enumerate(dictionary_data):
                try:
                    term = item.get('term', f'term_{i}')
                    category = item.get('category', 'Component')
                    definition = item.get('definition', '')
                    aliases = item.get('aliases', [])
                    tags = item.get('tags', [])
                    
                    # ç¡®ä¿categoryæ˜¯æœ‰æ•ˆçš„æ ‡ç­¾
                    valid_categories = ['Component', 'Symptom', 'Tool', 'Process', 'TestCase', 'Material', 'Role', 'Metric']
                    if category not in valid_categories:
                        category = 'Component'
                    
                    # å¤„ç†æ ‡ç­¾å’Œåˆ«å
                    if isinstance(aliases, str):
                        aliases = [aliases] if aliases else []
                    if isinstance(tags, str):
                        tags = [tags] if tags else []
                    
                    # åˆ›å»ºèŠ‚ç‚¹
                    session.run(f"""
                        CREATE (n:{category})
                        SET n.name = $term,
                            n.term = $term,
                            n.definition = $definition,
                            n.description = $definition,
                            n.aliases = $aliases,
                            n.tags = $tags,
                            n.category = $category,
                            n.source = 'dictionary',
                            n.created_at = datetime(),
                            n.updated_at = datetime()
                    """, term=term, definition=definition, aliases=aliases, tags=tags, category=category)
                    
                    imported_count += 1
                    category_counts[category] = category_counts.get(category, 0) + 1
                    
                    if imported_count % 100 == 0:
                        print(f"  å·²å¯¼å…¥ {imported_count}/{len(dictionary_data)} ä¸ªèŠ‚ç‚¹")
                        
                except Exception as e:
                    print(f"âŒ å¯¼å…¥èŠ‚ç‚¹å¤±è´¥: {item.get('term', f'item_{i}')} - {e}")
        
        print(f"\nâœ… è¯å…¸æ•°æ®å¯¼å…¥å®Œæˆ:")
        print(f"  æ€»è®¡: {imported_count} ä¸ªèŠ‚ç‚¹")
        for category, count in sorted(category_counts.items()):
            print(f"  {category}: {count} ä¸ª")
        
        return imported_count, category_counts
    
    def create_smart_relationships(self):
        """åˆ›å»ºæ™ºèƒ½å…³ç³»"""
        print("\nğŸ”— åˆ›å»ºæ™ºèƒ½å…³ç³»")
        print("=" * 50)
        
        total_created = 0
        
        with self.driver.session() as session:
            # 1. Component -> Symptom (ç»„ä»¶æœ‰ç—‡çŠ¶)
            print("  åˆ›å»º Component -> Symptom å…³ç³»...")
            result1 = session.run("""
                MATCH (c:Component), (s:Symptom)
                WHERE size(c.tags) > 0 AND size(s.tags) > 0
                WITH c, s, [tag IN c.tags WHERE tag IN s.tags] as common_tags
                WHERE size(common_tags) >= 1
                MERGE (c)-[r:HAS_SYMPTOM]->(s)
                SET r.confidence = toFloat(size(common_tags)) / 5.0,
                    r.source = 'tag_similarity',
                    r.created_at = datetime()
                RETURN count(r) as created
            """)
            created1 = result1.single()['created'] if result1.single() else 0
            total_created += created1
            print(f"    åˆ›å»ºäº† {created1} ä¸ª HAS_SYMPTOM å…³ç³»")
            
            # 2. TestCase -> Tool (æµ‹è¯•ç”¨ä¾‹ä½¿ç”¨å·¥å…·)
            print("  åˆ›å»º TestCase -> Tool å…³ç³»...")
            result2 = session.run("""
                MATCH (tc:TestCase), (t:Tool)
                WHERE size(tc.tags) > 0 AND size(t.tags) > 0
                WITH tc, t, [tag IN tc.tags WHERE tag IN t.tags] as common_tags
                WHERE size(common_tags) >= 1
                MERGE (tc)-[r:USES_TOOL]->(t)
                SET r.confidence = toFloat(size(common_tags)) / 5.0,
                    r.source = 'tag_similarity',
                    r.created_at = datetime()
                RETURN count(r) as created
            """)
            created2 = result2.single()['created'] if result2.single() else 0
            total_created += created2
            print(f"    åˆ›å»ºäº† {created2} ä¸ª USES_TOOL å…³ç³»")
            
            # 3. TestCase -> Metric (æµ‹è¯•ç”¨ä¾‹æµ‹é‡æŒ‡æ ‡)
            print("  åˆ›å»º TestCase -> Metric å…³ç³»...")
            result3 = session.run("""
                MATCH (tc:TestCase), (m:Metric)
                WHERE size(tc.tags) > 0 AND size(m.tags) > 0
                WITH tc, m, [tag IN tc.tags WHERE tag IN m.tags] as common_tags
                WHERE size(common_tags) >= 1
                MERGE (tc)-[r:MEASURES]->(m)
                SET r.confidence = toFloat(size(common_tags)) / 5.0,
                    r.source = 'tag_similarity',
                    r.created_at = datetime()
                RETURN count(r) as created
            """)
            created3 = result3.single()['created'] if result3.single() else 0
            total_created += created3
            print(f"    åˆ›å»ºäº† {created3} ä¸ª MEASURES å…³ç³»")
            
            # 4. Process -> Material (æµç¨‹ä½¿ç”¨ææ–™)
            print("  åˆ›å»º Process -> Material å…³ç³»...")
            result4 = session.run("""
                MATCH (p:Process), (m:Material)
                WHERE size(p.tags) > 0 AND size(m.tags) > 0
                WITH p, m, [tag IN p.tags WHERE tag IN m.tags] as common_tags
                WHERE size(common_tags) >= 1
                MERGE (p)-[r:USES_MATERIAL]->(m)
                SET r.confidence = toFloat(size(common_tags)) / 5.0,
                    r.source = 'tag_similarity',
                    r.created_at = datetime()
                RETURN count(r) as created
            """)
            created4 = result4.single()['created'] if result4.single() else 0
            total_created += created4
            print(f"    åˆ›å»ºäº† {created4} ä¸ª USES_MATERIAL å…³ç³»")
            
            # 5. Process -> Tool (æµç¨‹ä½¿ç”¨å·¥å…·)
            print("  åˆ›å»º Process -> Tool å…³ç³»...")
            result5 = session.run("""
                MATCH (p:Process), (t:Tool)
                WHERE size(p.tags) > 0 AND size(t.tags) > 0
                WITH p, t, [tag IN p.tags WHERE tag IN t.tags] as common_tags
                WHERE size(common_tags) >= 1
                MERGE (p)-[r:USES_TOOL]->(t)
                SET r.confidence = toFloat(size(common_tags)) / 5.0,
                    r.source = 'tag_similarity',
                    r.created_at = datetime()
                RETURN count(r) as created
            """)
            created5 = result5.single()['created'] if result5.single() else 0
            total_created += created5
            print(f"    åˆ›å»ºäº† {created5} ä¸ª USES_TOOL å…³ç³»")
            
            # 6. Component -> Component (ç›¸å…³ç»„ä»¶)
            print("  åˆ›å»º Component -> Component å…³ç³»...")
            result6 = session.run("""
                MATCH (c1:Component), (c2:Component)
                WHERE id(c1) < id(c2)
                AND size(c1.tags) > 0 AND size(c2.tags) > 0
                WITH c1, c2, [tag IN c1.tags WHERE tag IN c2.tags] as common_tags
                WHERE size(common_tags) >= 2
                MERGE (c1)-[r:RELATED_TO]->(c2)
                SET r.confidence = toFloat(size(common_tags)) / 5.0,
                    r.source = 'tag_similarity',
                    r.created_at = datetime()
                RETURN count(r) as created
            """)
            created6 = result6.single()['created'] if result6.single() else 0
            total_created += created6
            print(f"    åˆ›å»ºäº† {created6} ä¸ª RELATED_TO å…³ç³»")
        
        print(f"\nâœ… å…³ç³»åˆ›å»ºå®Œæˆï¼Œæ€»è®¡: {total_created} ä¸ª")
        return total_created
    
    def verify_final_result(self):
        """éªŒè¯æœ€ç»ˆç»“æœ"""
        print("\nğŸ” éªŒè¯æœ€ç»ˆç»“æœ")
        print("=" * 50)
        
        with self.driver.session() as session:
            # èŠ‚ç‚¹ç»Ÿè®¡
            node_result = session.run("""
                MATCH (n)
                WHERE n:Component OR n:Symptom OR n:Tool OR n:Process OR n:TestCase OR n:Material OR n:Role OR n:Metric
                RETURN labels(n)[0] as label, count(n) as count
                ORDER BY count DESC
            """)
            
            total_nodes = 0
            print("ğŸ“Š æœ€ç»ˆèŠ‚ç‚¹åˆ†å¸ƒ:")
            for record in node_result:
                count = record['count']
                total_nodes += count
                print(f"  {record['label']}: {count} ä¸ª")
            
            # å…³ç³»ç»Ÿè®¡
            rel_result = session.run("""
                MATCH ()-[r]->()
                RETURN type(r) as rel_type, count(r) as count
                ORDER BY count DESC
            """)
            
            total_rels = 0
            print(f"\nğŸ”— æœ€ç»ˆå…³ç³»åˆ†å¸ƒ:")
            for record in rel_result:
                count = record['count']
                total_rels += count
                print(f"  {record['rel_type']}: {count} ä¸ª")
            
            print(f"\nğŸ“ˆ æœ€ç»ˆæ€»è®¡:")
            print(f"  èŠ‚ç‚¹æ•°: {total_nodes}")
            print(f"  å…³ç³»æ•°: {total_rels}")
            
            # éªŒè¯ç»“æœ
            if total_nodes == 1124:
                print(f"ğŸ‰ èŠ‚ç‚¹æ•°å®Œç¾ï¼æ­£å¥½æ˜¯1124æ¡è¯å…¸æ•°æ®")
            elif abs(total_nodes - 1124) <= 10:
                print(f"âœ… èŠ‚ç‚¹æ•°æ¥è¿‘é¢„æœŸï¼Œå·®å¼‚åœ¨å¯æ¥å—èŒƒå›´å†…")
            else:
                print(f"âš ï¸ èŠ‚ç‚¹æ•°ä¸é¢„æœŸå·®å¼‚è¾ƒå¤§")
            
            if total_rels >= 1000:
                print(f"ğŸ‰ å…³ç³»æ•°å……è¶³ï¼")
            else:
                print(f"âš ï¸ å…³ç³»æ•°è¾ƒå°‘ï¼Œå¯èƒ½éœ€è¦ä¼˜åŒ–å…³ç³»åˆ›å»ºè§„åˆ™")
            
            return total_nodes, total_rels

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ å¿«é€Ÿé‡å»ºå›¾è°±æ•°æ®")
    print("=" * 80)
    
    rebuilder = QuickGraphRebuilder()
    
    try:
        # 1. åˆ†æå½“å‰æ•°æ®
        current_nodes, current_rels = rebuilder.analyze_current_data()
        
        print(f"\nâš ï¸ å³å°†æ¸…ç©ºæ‰€æœ‰æ•°æ®å¹¶é‡å»º")
        print(f"å½“å‰æ•°æ®: {current_nodes} ä¸ªèŠ‚ç‚¹, {current_rels} ä¸ªå…³ç³»")
        response = input("ç¡®è®¤ç»§ç»­ï¼Ÿ(y/n): ").strip().lower()
        
        if response != 'y':
            print("âŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
            return
        
        # 2. æ¸…ç©ºæ‰€æœ‰æ•°æ®
        deleted_nodes, deleted_rels = rebuilder.clear_all_data()
        
        # 3. å¯¼å…¥è¯å…¸æ•°æ®
        imported_count, category_counts = rebuilder.import_dictionary_data()
        
        # 4. åˆ›å»ºæ™ºèƒ½å…³ç³»
        relationships_created = rebuilder.create_smart_relationships()
        
        # 5. éªŒè¯ç»“æœ
        final_nodes, final_rels = rebuilder.verify_final_result()
        
        # 6. æ€»ç»“
        print(f"\n" + "=" * 80)
        print(f"ğŸ‰ å›¾è°±æ•°æ®é‡å»ºå®Œæˆï¼")
        print(f"=" * 80)
        
        print(f"ğŸ“Š é‡å»ºç»Ÿè®¡:")
        print(f"  åˆ é™¤èŠ‚ç‚¹: {deleted_nodes} ä¸ª")
        print(f"  åˆ é™¤å…³ç³»: {deleted_rels} ä¸ª")
        print(f"  å¯¼å…¥èŠ‚ç‚¹: {imported_count} ä¸ª")
        print(f"  åˆ›å»ºå…³ç³»: {relationships_created} ä¸ª")
        
        print(f"\nğŸ“ˆ æœ€ç»ˆç»“æœ:")
        print(f"  æ€»èŠ‚ç‚¹æ•°: {final_nodes} (ç›®æ ‡: 1124)")
        print(f"  æ€»å…³ç³»æ•°: {final_rels}")
        
        if final_nodes == 1124:
            print(f"\nğŸ‰ å®Œç¾ï¼å›¾è°±ç°åœ¨åŒ…å«çº¯å‡€çš„1124æ¡è¯å…¸æ•°æ®")
        
        print(f"\nğŸŒ ç°åœ¨å¯ä»¥è®¿é—®å‰ç«¯æŸ¥çœ‹é‡å»ºåçš„å›¾è°±:")
        print(f"  - å›¾è°±å¯è§†åŒ–: http://localhost:5173/#/graph-visualization")
        print(f"  - è¯å…¸ç®¡ç†: http://localhost:5173/#/dictionary")
        
    except Exception as e:
        print(f"âŒ é‡å»ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        rebuilder.close()

if __name__ == "__main__":
    main()
