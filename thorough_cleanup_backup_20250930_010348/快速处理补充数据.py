#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿå¤„ç†è¡¥å……è¯å…¸æ•°æ®
"""

import pandas as pd
import json
from datetime import datetime

def process_csv_files():
    """å¤„ç†CSVæ–‡ä»¶å¹¶ç”Ÿæˆç»Ÿè®¡"""
    
    # åŠ è½½æ•°æ®
    try:
        df1 = pd.read_csv('è¡¥å……è¯å…¸æ•°æ®_æ‰¹æ¬¡1.csv', encoding='utf-8')
        print(f"âœ… æ‰¹æ¬¡1: {len(df1)} æ¡è®°å½•")
    except Exception as e:
        print(f"âŒ æ‰¹æ¬¡1åŠ è½½å¤±è´¥: {e}")
        df1 = pd.DataFrame()
    
    try:
        df2 = pd.read_csv('è¡¥å……è¯å…¸æ•°æ®_æ‰¹æ¬¡2.csv', encoding='utf-8')
        print(f"âœ… æ‰¹æ¬¡2: {len(df2)} æ¡è®°å½•")
    except Exception as e:
        print(f"âŒ æ‰¹æ¬¡2åŠ è½½å¤±è´¥: {e}")
        df2 = pd.DataFrame()
    
    # åˆå¹¶æ•°æ®
    if not df1.empty and not df2.empty:
        df_all = pd.concat([df1, df2], ignore_index=True)
    elif not df1.empty:
        df_all = df1
    elif not df2.empty:
        df_all = df2
    else:
        print("âŒ æ²¡æœ‰å¯ç”¨æ•°æ®")
        return
    
    print(f"ğŸ“Š æ€»è®¡: {len(df_all)} æ¡æ–°æ•°æ®")
    
    # æŒ‰Labelç»Ÿè®¡
    label_stats = df_all['category'].value_counts().to_dict()
    print("\nğŸ“‹ æŒ‰Labelåˆ†å¸ƒ:")
    for label, count in sorted(label_stats.items(), key=lambda x: x[1], reverse=True):
        print(f"  {label}: {count}æ¡")
    
    # é‡ç‚¹å…³æ³¨Materialå’ŒRole
    material_count = label_stats.get('Material', 0)
    role_count = label_stats.get('Role', 0)
    print(f"\nğŸ¯ é‡ç‚¹è¡¥å……:")
    print(f"  Material: {material_count}æ¡")
    print(f"  Role: {role_count}æ¡")
    
    # ç”ŸæˆCypherè„šæœ¬
    cypher_statements = []
    for _, row in df_all.iterrows():
        term = row['term']
        category = row['category']
        
        # å¤„ç†åˆ«å
        aliases = []
        if pd.notna(row.get('aliases', '')):
            aliases = [alias.strip() for alias in str(row['aliases']).split(';') if alias.strip()]
        
        # å¤„ç†æ ‡ç­¾
        tags = []
        if pd.notna(row.get('tags', '')):
            tags = [tag.strip() for tag in str(row['tags']).split(';') if tag.strip()]
        
        # æ„å»ºå±æ€§
        properties = []
        properties.append(f"name: '{term.replace(chr(39), chr(39)+chr(39))}'")  # è½¬ä¹‰å•å¼•å·
        
        if aliases:
            aliases_str = str(aliases).replace("'", '"')
            properties.append(f"aliases: {aliases_str}")
        
        if tags:
            tags_str = str(tags).replace("'", '"')
            properties.append(f"tags: {tags_str}")
        
        if pd.notna(row.get('definition', '')):
            definition = str(row['definition']).replace("'", "''")
            properties.append(f"definition: '{definition}'")
        
        if pd.notna(row.get('example', '')):
            example = str(row['example']).replace("'", "''")
            properties.append(f"example: '{example}'")
        
        if pd.notna(row.get('sub_category', '')):
            sub_category = str(row['sub_category']).replace("'", "''")
            properties.append(f"sub_category: '{sub_category}'")
        
        properties.append(f"source: 'æ ‡å‡†åŒ–è¯å…¸'")
        properties.append(f"status: 'active'")
        properties.append(f"updated_at: '{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}'")
        
        properties_str = ', '.join(properties)
        cypher = f"CREATE (:{category} {{{properties_str}}});"
        cypher_statements.append(cypher)
    
    # ä¿å­˜Cypherè„šæœ¬
    with open('è¡¥å……æ•°æ®å¯¼å…¥è„šæœ¬.cypher', 'w', encoding='utf-8') as f:
        f.write("// è¡¥å……è¯å…¸æ•°æ®å¯¼å…¥è„šæœ¬\n")
        f.write(f"// ç”Ÿæˆæ—¶é—´: {datetime.now().isoformat()}\n")
        f.write(f"// æ€»è®¡: {len(cypher_statements)}æ¡æ–°æ•°æ®\n\n")
        
        for statement in cypher_statements:
            f.write(statement + "\n")
    
    print(f"\nâœ… Cypherè„šæœ¬å·²ç”Ÿæˆ: è¡¥å……æ•°æ®å¯¼å…¥è„šæœ¬.cypher")
    print(f"åŒ…å« {len(cypher_statements)} æ¡CREATEè¯­å¥")
    
    # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
    report = {
        'generation_time': datetime.now().isoformat(),
        'total_records': len(df_all),
        'label_distribution': label_stats,
        'files_generated': ['è¡¥å……æ•°æ®å¯¼å…¥è„šæœ¬.cypher'],
        'key_additions': {
            'Material': material_count,
            'Role': role_count
        }
    }
    
    with open('è¡¥å……æ•°æ®ç»Ÿè®¡æŠ¥å‘Š.json', 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ç»Ÿè®¡æŠ¥å‘Šå·²ç”Ÿæˆ: è¡¥å……æ•°æ®ç»Ÿè®¡æŠ¥å‘Š.json")
    
    return len(df_all), label_stats

def main():
    print("ğŸš€ å¿«é€Ÿå¤„ç†è¡¥å……è¯å…¸æ•°æ®...")
    
    total, stats = process_csv_files()
    
    print(f"\nğŸ“ˆ å¤„ç†å®Œæˆ!")
    print(f"æ€»è®¡å¤„ç†: {total}æ¡æ–°æ•°æ®")
    print(f"Materialç±»åˆ«: {stats.get('Material', 0)}æ¡")
    print(f"Roleç±»åˆ«: {stats.get('Role', 0)}æ¡")
    
    print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥:")
    print(f"1. ç­‰å¾…Neo4jè®¤è¯é—®é¢˜è§£å†³")
    print(f"2. æ‰§è¡Œç”Ÿæˆçš„Cypherè„šæœ¬å¯¼å…¥æ•°æ®")
    print(f"3. éªŒè¯æ•°æ®å¯¼å…¥ç»“æœ")

if __name__ == "__main__":
    main()
