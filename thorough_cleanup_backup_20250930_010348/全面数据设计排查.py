#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å…¨é¢æ’æŸ¥è¯å…¸å’Œå…³ç³»æ•°æ®è®¾è®¡é—®é¢˜
åˆ†ææ•°æ®åå·®çš„æ ¹æœ¬åŸå› 
"""

import requests
import json
import time
from neo4j import GraphDatabase
from datetime import datetime
import pandas as pd

def check_neo4j_connection():
    """æ£€æŸ¥Neo4jè¿æ¥å’Œè®¤è¯"""
    print("ğŸ”— æ£€æŸ¥Neo4jè¿æ¥...")
    
    uri = "bolt://localhost:7687"
    passwords = ["password123", "neo4j", "admin", "password", "123456"]
    
    for password in passwords:
        try:
            driver = GraphDatabase.driver(uri, auth=("neo4j", password))
            with driver.session() as session:
                result = session.run("RETURN 1 as test")
                test_value = result.single()["test"]
                if test_value == 1:
                    print(f"âœ… Neo4jè¿æ¥æˆåŠŸ (å¯†ç : {password})")
                    driver.close()
                    return password
        except Exception as e:
            if "AuthenticationRateLimit" not in str(e):
                print(f"âŒ å¯†ç  '{password}' å¤±è´¥: {str(e)[:100]}")
            continue
    
    print("âŒ æ— æ³•è¿æ¥Neo4j")
    return None

def analyze_current_data_structure():
    """åˆ†æå½“å‰æ•°æ®ç»“æ„"""
    print("\nğŸ“Š åˆ†æå½“å‰æ•°æ®ç»“æ„...")
    
    password = check_neo4j_connection()
    if not password:
        print("âŒ æ— æ³•è¿æ¥Neo4jï¼Œè·³è¿‡æ•°æ®ç»“æ„åˆ†æ")
        return None
    
    try:
        driver = GraphDatabase.driver("bolt://localhost:7687", auth=("neo4j", password))
        
        with driver.session() as session:
            # 1. æ£€æŸ¥æ‰€æœ‰æ ‡ç­¾
            print("\n1. å½“å‰æ•°æ®åº“æ ‡ç­¾:")
            result = session.run("CALL db.labels()")
            labels = [record["label"] for record in result]
            print(f"   æ ‡ç­¾æ•°é‡: {len(labels)}")
            for label in sorted(labels):
                count_result = session.run(f"MATCH (n:{label}) RETURN count(n) as count")
                count = count_result.single()["count"]
                print(f"   - {label}: {count} ä¸ªèŠ‚ç‚¹")
            
            # 2. æ£€æŸ¥å…³ç³»ç±»å‹
            print("\n2. å½“å‰å…³ç³»ç±»å‹:")
            result = session.run("CALL db.relationshipTypes()")
            rel_types = [record["relationshipType"] for record in result]
            print(f"   å…³ç³»ç±»å‹æ•°é‡: {len(rel_types)}")
            for rel_type in sorted(rel_types):
                count_result = session.run(f"MATCH ()-[r:{rel_type}]-() RETURN count(r) as count")
                count = count_result.single()["count"]
                print(f"   - {rel_type}: {count} ä¸ªå…³ç³»")
            
            # 3. æ£€æŸ¥DictionaryèŠ‚ç‚¹ç»“æ„
            print("\n3. DictionaryèŠ‚ç‚¹ç»“æ„åˆ†æ:")
            result = session.run("""
                MATCH (d:Dictionary) 
                RETURN d.category as category, count(*) as count 
                ORDER BY count DESC LIMIT 10
            """)
            
            categories = list(result)
            if categories:
                print("   æŒ‰ç±»åˆ«åˆ†å¸ƒ:")
                for record in categories:
                    category = record["category"] or "æœªåˆ†ç±»"
                    count = record["count"]
                    print(f"   - {category}: {count} ä¸ª")
            else:
                print("   âŒ æ²¡æœ‰æ‰¾åˆ°DictionaryèŠ‚ç‚¹")
            
            # 4. æ£€æŸ¥é‡å¤æ•°æ®
            print("\n4. é‡å¤æ•°æ®æ£€æŸ¥:")
            
            # æ£€æŸ¥é‡å¤çš„DictionaryèŠ‚ç‚¹
            result = session.run("""
                MATCH (d:Dictionary)
                WITH d.term as term, d.category as category, count(*) as count
                WHERE count > 1
                RETURN term, category, count
                ORDER BY count DESC LIMIT 10
            """)
            
            duplicates = list(result)
            if duplicates:
                print("   å‘ç°é‡å¤DictionaryèŠ‚ç‚¹:")
                for record in duplicates:
                    print(f"   - '{record['term']}' ({record['category']}): {record['count']} ä¸ªé‡å¤")
            else:
                print("   âœ… æ²¡æœ‰å‘ç°é‡å¤DictionaryèŠ‚ç‚¹")
            
            # 5. æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
            print("\n5. æ•°æ®å®Œæ•´æ€§æ£€æŸ¥:")
            
            # æ£€æŸ¥ç¼ºå°‘å¿…è¦å±æ€§çš„èŠ‚ç‚¹
            result = session.run("""
                MATCH (d:Dictionary)
                WHERE d.term IS NULL OR d.term = ""
                RETURN count(*) as count
            """)
            empty_terms = result.single()["count"]
            if empty_terms > 0:
                print(f"   âŒ å‘ç° {empty_terms} ä¸ªç©ºtermçš„DictionaryèŠ‚ç‚¹")
            else:
                print("   âœ… æ‰€æœ‰DictionaryèŠ‚ç‚¹éƒ½æœ‰termå±æ€§")
            
            # æ£€æŸ¥å­¤ç«‹èŠ‚ç‚¹
            result = session.run("""
                MATCH (d:Dictionary)
                WHERE NOT (d)-[]-()
                RETURN count(*) as count
            """)
            isolated = result.single()["count"]
            if isolated > 0:
                print(f"   âš ï¸ å‘ç° {isolated} ä¸ªå­¤ç«‹çš„DictionaryèŠ‚ç‚¹")
            else:
                print("   âœ… æ²¡æœ‰å­¤ç«‹çš„DictionaryèŠ‚ç‚¹")
        
        driver.close()
        return {
            "labels": labels,
            "relationships": rel_types,
            "categories": categories,
            "duplicates": duplicates,
            "empty_terms": empty_terms,
            "isolated": isolated
        }
        
    except Exception as e:
        print(f"âŒ æ•°æ®ç»“æ„åˆ†æå¤±è´¥: {e}")
        return None

def check_api_data_consistency():
    """æ£€æŸ¥APIæ•°æ®ä¸€è‡´æ€§"""
    print("\nğŸ” æ£€æŸ¥APIæ•°æ®ä¸€è‡´æ€§...")
    
    try:
        # 1. æ£€æŸ¥è¯å…¸ç»Ÿè®¡
        print("1. è¯å…¸ç»Ÿè®¡æ£€æŸ¥:")
        response = requests.get("http://localhost:8000/kg/dictionary/stats", timeout=10)
        if response.status_code == 200:
            stats = response.json()
            if stats.get("success"):
                data = stats.get("data", {})
                print(f"   APIæŠ¥å‘Šè¯å…¸æ¡ç›®: {data.get('total_terms', 0)}")
                print(f"   APIæŠ¥å‘Šç±»åˆ«æ•°: {data.get('total_categories', 0)}")
                
                categories = data.get("categories", [])
                if categories:
                    print("   ç±»åˆ«åˆ†å¸ƒ:")
                    for cat in categories[:10]:  # æ˜¾ç¤ºå‰10ä¸ª
                        print(f"   - {cat.get('category', 'æœªçŸ¥')}: {cat.get('count', 0)} ä¸ª")
            else:
                print(f"   âŒ APIè¿”å›é”™è¯¯: {stats.get('message')}")
        else:
            print(f"   âŒ APIè¯·æ±‚å¤±è´¥: HTTP {response.status_code}")
        
        # 2. æ£€æŸ¥å›¾è°±ç»Ÿè®¡
        print("\n2. å›¾è°±ç»Ÿè®¡æ£€æŸ¥:")
        response = requests.get("http://localhost:8000/kg/graph/stats", timeout=10)
        if response.status_code == 200:
            stats = response.json()
            if stats.get("success"):
                data = stats.get("data", {})
                print(f"   APIæŠ¥å‘ŠèŠ‚ç‚¹æ•°: {data.get('total_nodes', 0)}")
                print(f"   APIæŠ¥å‘Šå…³ç³»æ•°: {data.get('total_relationships', 0)}")
                
                node_types = data.get("node_types", [])
                if node_types:
                    print("   èŠ‚ç‚¹ç±»å‹åˆ†å¸ƒ:")
                    for nt in node_types:
                        print(f"   - {nt.get('label', 'æœªçŸ¥')}: {nt.get('count', 0)} ä¸ª")
            else:
                print(f"   âŒ APIè¿”å›é”™è¯¯: {stats.get('message')}")
        else:
            print(f"   âŒ APIè¯·æ±‚å¤±è´¥: HTTP {response.status_code}")
        
        return True
        
    except Exception as e:
        print(f"âŒ APIæ•°æ®ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥: {e}")
        return False

def identify_data_inconsistency_causes():
    """è¯†åˆ«æ•°æ®ä¸ä¸€è‡´çš„åŸå› """
    print("\nğŸ” è¯†åˆ«æ•°æ®ä¸ä¸€è‡´åŸå› ...")
    
    potential_causes = []
    
    # 1. æ£€æŸ¥é…ç½®æ–‡ä»¶
    print("1. æ£€æŸ¥é…ç½®æ–‡ä»¶:")
    config_files = [
        "api/unified_dictionary_config.py",
        "config/system_management_config.json",
        "data/unified_dictionary/schema.json"
    ]
    
    for config_file in config_files:
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                content = f.read()
                if "Dictionary" in content:
                    print(f"   âœ… æ‰¾åˆ°é…ç½®æ–‡ä»¶: {config_file}")
                else:
                    print(f"   âš ï¸ é…ç½®æ–‡ä»¶å¯èƒ½æœ‰é—®é¢˜: {config_file}")
                    potential_causes.append(f"é…ç½®æ–‡ä»¶é—®é¢˜: {config_file}")
        except FileNotFoundError:
            print(f"   âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
            potential_causes.append(f"ç¼ºå°‘é…ç½®æ–‡ä»¶: {config_file}")
        except Exception as e:
            print(f"   âŒ è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {config_file} - {e}")
    
    # 2. æ£€æŸ¥æ•°æ®å¯¼å…¥è„šæœ¬
    print("\n2. æ£€æŸ¥æ•°æ®å¯¼å…¥è„šæœ¬:")
    import_scripts = [
        "å¯¼å…¥æ‰¹æ¬¡_01.cypher",
        "å¯¼å…¥æ‰¹æ¬¡_02.cypher", 
        "å®Œæ•´è¯å…¸è¡¥å……æ•°æ®å¯¼å…¥è„šæœ¬.cypher"
    ]
    
    for script in import_scripts:
        try:
            with open(script, 'r', encoding='utf-8') as f:
                content = f.read()
                if "CREATE" in content and "Dictionary" in content:
                    print(f"   âœ… æ‰¾åˆ°å¯¼å…¥è„šæœ¬: {script}")
                    # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤å¯¼å…¥
                    if "MERGE" not in content and content.count("CREATE") > 100:
                        print(f"      âš ï¸ è„šæœ¬ä½¿ç”¨CREATEè€ŒéMERGEï¼Œå¯èƒ½å¯¼è‡´é‡å¤æ•°æ®")
                        potential_causes.append(f"é‡å¤å¯¼å…¥é£é™©: {script}")
        except FileNotFoundError:
            print(f"   âš ï¸ å¯¼å…¥è„šæœ¬ä¸å­˜åœ¨: {script}")
        except Exception as e:
            print(f"   âŒ è¯»å–å¯¼å…¥è„šæœ¬å¤±è´¥: {script} - {e}")
    
    # 3. æ£€æŸ¥APIå¯åŠ¨æ—¶çš„æ•°æ®åˆå§‹åŒ–
    print("\n3. æ£€æŸ¥APIå¯åŠ¨æ—¶çš„æ•°æ®åˆå§‹åŒ–:")
    try:
        with open("api/main.py", 'r', encoding='utf-8') as f:
            content = f.read()
            if "startup" in content.lower() or "initialize" in content.lower():
                print("   âœ… APIæœ‰å¯åŠ¨åˆå§‹åŒ–é€»è¾‘")
                if "dictionary" in content.lower():
                    print("   âš ï¸ APIå¯åŠ¨æ—¶å¯èƒ½é‡æ–°åˆå§‹åŒ–è¯å…¸æ•°æ®")
                    potential_causes.append("APIå¯åŠ¨æ—¶é‡æ–°åˆå§‹åŒ–æ•°æ®")
            else:
                print("   âœ… APIæ²¡æœ‰å¯åŠ¨åˆå§‹åŒ–é€»è¾‘")
    except Exception as e:
        print(f"   âŒ æ£€æŸ¥APIå¯åŠ¨é€»è¾‘å¤±è´¥: {e}")
    
    return potential_causes

def generate_fix_recommendations(causes, data_analysis):
    """ç”Ÿæˆä¿®å¤å»ºè®®"""
    print("\nğŸ’¡ ä¿®å¤å»ºè®®:")
    print("=" * 50)
    
    recommendations = []
    
    # åŸºäºå‘ç°çš„é—®é¢˜ç”Ÿæˆå»ºè®®
    if data_analysis and data_analysis.get("duplicates"):
        recommendations.append({
            "é—®é¢˜": "å‘ç°é‡å¤æ•°æ®",
            "å»ºè®®": "æ‰§è¡Œå»é‡è„šæœ¬ï¼Œä½¿ç”¨MERGEæ›¿ä»£CREATE",
            "ä¼˜å…ˆçº§": "é«˜"
        })
    
    if data_analysis and data_analysis.get("empty_terms", 0) > 0:
        recommendations.append({
            "é—®é¢˜": "å­˜åœ¨ç©ºtermçš„èŠ‚ç‚¹",
            "å»ºè®®": "æ¸…ç†æ— æ•ˆæ•°æ®èŠ‚ç‚¹",
            "ä¼˜å…ˆçº§": "ä¸­"
        })
    
    if "APIå¯åŠ¨æ—¶é‡æ–°åˆå§‹åŒ–æ•°æ®" in causes:
        recommendations.append({
            "é—®é¢˜": "APIå¯åŠ¨æ—¶é‡å¤åˆå§‹åŒ–",
            "å»ºè®®": "ä¿®æ”¹APIå¯åŠ¨é€»è¾‘ï¼Œé¿å…é‡å¤åˆå§‹åŒ–",
            "ä¼˜å…ˆçº§": "é«˜"
        })
    
    if any("é‡å¤å¯¼å…¥" in cause for cause in causes):
        recommendations.append({
            "é—®é¢˜": "å¯¼å…¥è„šæœ¬å¯èƒ½é‡å¤æ‰§è¡Œ",
            "å»ºè®®": "ä½¿ç”¨MERGEè¯­å¥æ›¿ä»£CREATEï¼Œæ·»åŠ å”¯ä¸€æ€§çº¦æŸ",
            "ä¼˜å…ˆçº§": "é«˜"
        })
    
    # é€šç”¨å»ºè®®
    recommendations.extend([
        {
            "é—®é¢˜": "æ•°æ®ä¸€è‡´æ€§ä¿è¯",
            "å»ºè®®": "å»ºç«‹æ•°æ®ç‰ˆæœ¬æ§åˆ¶å’Œæ ¡éªŒæœºåˆ¶",
            "ä¼˜å…ˆçº§": "ä¸­"
        },
        {
            "é—®é¢˜": "å¯åŠ¨æ—¶æ•°æ®åå·®",
            "å»ºè®®": "å®ç°å¹‚ç­‰æ€§æ•°æ®åˆå§‹åŒ–",
            "ä¼˜å…ˆçº§": "é«˜"
        }
    ])
    
    for i, rec in enumerate(recommendations, 1):
        priority_icon = "ğŸ”´" if rec["ä¼˜å…ˆçº§"] == "é«˜" else "ğŸŸ¡" if rec["ä¼˜å…ˆçº§"] == "ä¸­" else "ğŸŸ¢"
        print(f"{i}. {priority_icon} {rec['é—®é¢˜']}")
        print(f"   å»ºè®®: {rec['å»ºè®®']}")
        print()
    
    return recommendations

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” å…¨é¢æ•°æ®è®¾è®¡æ’æŸ¥")
    print("=" * 60)
    print(f"ğŸ•’ æ£€æŸ¥æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # 1. åˆ†æå½“å‰æ•°æ®ç»“æ„
    data_analysis = analyze_current_data_structure()
    
    # 2. æ£€æŸ¥APIæ•°æ®ä¸€è‡´æ€§
    api_consistent = check_api_data_consistency()
    
    # 3. è¯†åˆ«ä¸ä¸€è‡´åŸå› 
    causes = identify_data_inconsistency_causes()
    
    # 4. ç”Ÿæˆä¿®å¤å»ºè®®
    recommendations = generate_fix_recommendations(causes, data_analysis)
    
    # 5. ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    print("\nğŸ“‹ é—®é¢˜æ€»ç»“:")
    print("=" * 50)
    
    if causes:
        print("ğŸ”´ å‘ç°çš„æ½œåœ¨é—®é¢˜:")
        for i, cause in enumerate(causes, 1):
            print(f"   {i}. {cause}")
    else:
        print("âœ… æ²¡æœ‰å‘ç°æ˜æ˜¾çš„é…ç½®é—®é¢˜")
    
    print(f"\nğŸ“Š æ•°æ®çŠ¶æ€:")
    if data_analysis:
        print(f"   - æ ‡ç­¾æ•°é‡: {len(data_analysis.get('labels', []))}")
        print(f"   - å…³ç³»ç±»å‹: {len(data_analysis.get('relationships', []))}")
        print(f"   - é‡å¤æ•°æ®: {len(data_analysis.get('duplicates', []))}")
        print(f"   - ç©ºtermèŠ‚ç‚¹: {data_analysis.get('empty_terms', 0)}")
        print(f"   - å­¤ç«‹èŠ‚ç‚¹: {data_analysis.get('isolated', 0)}")
    
    print(f"\nğŸ¯ ä¸‹ä¸€æ­¥è¡ŒåŠ¨:")
    print("   1. æ ¹æ®ä¿®å¤å»ºè®®ä¼˜å…ˆå¤„ç†é«˜ä¼˜å…ˆçº§é—®é¢˜")
    print("   2. å®æ–½æ•°æ®å»é‡å’Œæ¸…ç†")
    print("   3. ä¿®æ”¹å¯åŠ¨é€»è¾‘ç¡®ä¿å¹‚ç­‰æ€§")
    print("   4. å»ºç«‹æ•°æ®ä¸€è‡´æ€§ç›‘æ§")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"\nâŒ æ’æŸ¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
